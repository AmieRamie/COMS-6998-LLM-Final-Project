{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "ae40a52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai\n",
    "from google.oauth2 import service_account\n",
    "from google.auth import load_credentials_from_file\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "from PyPDF2 import PdfReader, PdfWriter\n",
    "from bs4 import BeautifulSoup\n",
    "import pdfplumber  # for improved OCR if needed\n",
    "import timeit\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List\n",
    "import tiktoken  # OpenAI's tokenization library\n",
    "import json\n",
    "import openai\n",
    "from googlesearch import search\n",
    "import unicodedata\n",
    "import urllib.parse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a907a022",
   "metadata": {},
   "source": [
    "<h1>1. Chunk data from lecture presentations</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b45ea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_pdf(input_pdf_path,file_name, max_pages=1):\n",
    "    \"\"\"\n",
    "    Split a PDF into smaller chunks of max_pages.\n",
    "    \"\"\"\n",
    "    reader = PdfReader(input_pdf_path)\n",
    "    chunks = []\n",
    "    for i in range(0, len(reader.pages), max_pages):\n",
    "        writer = PdfWriter()\n",
    "        for j in range(i, min(i + max_pages, len(reader.pages))):\n",
    "            writer.add_page(reader.pages[j])\n",
    "        chunk_path = f\"./chunks/chunk_{i // max_pages + 1}_{file_name.split('.')[0]}.pdf\"\n",
    "        with open(chunk_path, \"wb\") as f:\n",
    "            writer.write(f)\n",
    "        chunks.append(chunk_path)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "163d817a",
   "metadata": {},
   "outputs": [],
   "source": [
    "credentials = service_account.Credentials.from_service_account_file('coms-6998-applied-llm-class-4e98f4f7a361.json')\n",
    "client = documentai.DocumentProcessorServiceClient(credentials=credentials)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "a708ad6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_to_extract_data_from = os.listdir('./lecture_pdfs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21a5361f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_chunks = []\n",
    "for file_name in all_files_to_extract_data_from:\n",
    "    file_directory = \"./lecture_pdfs\"\n",
    "    pdf_path = os.path.join(file_directory, file_name)\n",
    "    chunks = split_pdf(pdf_path,file_name)\n",
    "    all_chunks = all_chunks + chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de21d848",
   "metadata": {},
   "source": [
    "<h1>2. Extract text and links from chunks from lectures</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6c8f9acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_links(text):\n",
    "    links = []\n",
    "    text = text.replace('-\\n',\"\")\n",
    "    page_links = re.findall(r'(https?://\\S+)', text)\n",
    "    links.extend(page_links)\n",
    "    page_links = re.findall(r'(http?://\\S+)', text)\n",
    "    links.extend(page_links)\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "475cff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_extraction(file_name,project_id = \"coms-6998-applied-llm-class\",location = \"us\",processor_id = \"398fd74279aa6748\"):\n",
    "    with open(file_name, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    raw_document = documentai.RawDocument(content=content, mime_type=\"application/pdf\")\n",
    "    name = f\"projects/{project_id}/locations/{location}/processors/{processor_id}\"\n",
    "    # Make the request\n",
    "    request = documentai.ProcessRequest(name=name, raw_document=raw_document)\n",
    "    response = client.process_document(request=request)\n",
    "    document = response.document\n",
    "    text = document.text\n",
    "    links = extract_text_links(text)\n",
    "    return text, links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5f8370b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_clean_text(url):\n",
    "    \"\"\"\n",
    "    Fetches and cleans text from the given URL.\n",
    "    :param url: The URL to fetch text from.\n",
    "    :return: Cleaned text or an error message.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Make an HTTP GET request\n",
    "        response = requests.get(url, timeout=5)\n",
    "        response.raise_for_status()  # Raise an HTTPError for bad responses (4xx and 5xx)\n",
    "        \n",
    "        # Parse the HTML content\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        \n",
    "        # Extract the main text content\n",
    "        # We can focus on specific tags (e.g., <p>, <div>) or use the whole text\n",
    "        text_elements = soup.find_all([\"p\", \"div\"])\n",
    "        text = \" \".join(element.get_text() for element in text_elements)\n",
    "        \n",
    "        # Clean the text\n",
    "        text = re.sub(r'\\s+', ' ', text)  # Remove extra whitespace\n",
    "        text = text.strip()  # Remove leading/trailing whitespace\n",
    "        \n",
    "        # Handle empty text scenario\n",
    "        if not text:\n",
    "            return f\"Error: No extractable text found at {url}\"\n",
    "        return text\n",
    "    \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        # Handle HTTP and connection errors\n",
    "        return f\"Error: Unable to fetch content from {url}. Exception: {e}\"\n",
    "    except Exception as e:\n",
    "        # Handle other unexpected errors\n",
    "        return f\"Error: Unexpected error while processing {url}. Exception: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "d9d38c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_links(links):\n",
    "    \"\"\"\n",
    "    Processes a list of links, extracting and cleaning text content.\n",
    "    :param links: List of URLs.\n",
    "    :return: Dictionary with URLs as keys and cleaned text (or error messages) as values.\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    for url in links:\n",
    "        print(f\"Processing: {url}\")\n",
    "        text = fetch_and_clean_text(url)\n",
    "        results[url] = text\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "3e78e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts_with_links = [value['text'] for key,value in all_data.items() if len(value['links'])>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "61de4ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45 6.449538166999446 ./chunks/chunk_46_Lecture-12-Columbia.pdf\n",
      "50 7.764267583000219 ./chunks/chunk_51_Lecture-12-Columbia.pdf\n",
      "55 7.30011899999954 ./chunks/chunk_56_Lecture-12-Columbia.pdf\n",
      "60 8.476970249999795 ./chunks/chunk_61_Lecture-12-Columbia.pdf\n",
      "65 8.502008792000197 ./chunks/chunk_66_Lecture-12-Columbia.pdf\n",
      "70 8.57982845800052 ./chunks/chunk_71_Lecture-12-Columbia.pdf\n",
      "75 7.840684208000312 ./chunks/chunk_76_Lecture-12-Columbia.pdf\n",
      "80 7.657551166999838 ./chunks/chunk_81_Lecture-12-Columbia.pdf\n",
      "85 7.173694291999709 ./chunks/chunk_86_Lecture-12-Columbia.pdf\n",
      "90 8.033632041000601 ./chunks/chunk_91_Lecture-12-Columbia.pdf\n",
      "95 8.131241334000151 ./chunks/chunk_96_Lecture-12-Columbia.pdf\n",
      "100 8.513085292000142 ./chunks/chunk_101_Lecture-12-Columbia.pdf\n",
      "105 7.703719500000261 ./chunks/chunk_106_Lecture-12-Columbia.pdf\n",
      "110 9.373608582999623 ./chunks/chunk_111_Lecture-12-Columbia.pdf\n",
      "115 8.92286362499999 ./chunks/chunk_116_Lecture-12-Columbia.pdf\n",
      "120 7.5701725419994546 ./chunks/chunk_121_Lecture-12-Columbia.pdf\n",
      "125 8.885581458999695 ./chunks/chunk_126_Lecture-12-Columbia.pdf\n",
      "130 9.089975707999656 ./chunks/chunk_131_Lecture-12-Columbia.pdf\n",
      "135 8.26253962499959 ./chunks/chunk_2_Lecture-13-Columbia.pdf\n",
      "140 8.236549958999603 ./chunks/chunk_7_Lecture-13-Columbia.pdf\n",
      "145 7.548319667000214 ./chunks/chunk_12_Lecture-13-Columbia.pdf\n",
      "150 7.327647166000133 ./chunks/chunk_17_Lecture-13-Columbia.pdf\n",
      "155 7.944368416000543 ./chunks/chunk_22_Lecture-13-Columbia.pdf\n",
      "160 7.962167457999385 ./chunks/chunk_27_Lecture-13-Columbia.pdf\n",
      "165 7.763841124999999 ./chunks/chunk_32_Lecture-13-Columbia.pdf\n",
      "170 8.528474917000494 ./chunks/chunk_37_Lecture-13-Columbia.pdf\n",
      "175 8.435918166000192 ./chunks/chunk_42_Lecture-13-Columbia.pdf\n",
      "180 8.159709958999883 ./chunks/chunk_47_Lecture-13-Columbia.pdf\n",
      "185 7.086496833000638 ./chunks/chunk_52_Lecture-13-Columbia.pdf\n",
      "190 7.783497625000564 ./chunks/chunk_57_Lecture-13-Columbia.pdf\n",
      "195 7.406822457999624 ./chunks/chunk_62_Lecture-13-Columbia.pdf\n",
      "200 7.861424958000498 ./chunks/chunk_67_Lecture-13-Columbia.pdf\n",
      "205 7.928558624999823 ./chunks/chunk_72_Lecture-13-Columbia.pdf\n",
      "210 7.78217662499992 ./chunks/chunk_77_Lecture-13-Columbia.pdf\n",
      "215 7.780537042000105 ./chunks/chunk_82_Lecture-13-Columbia.pdf\n",
      "220 7.842029082999943 ./chunks/chunk_87_Lecture-13-Columbia.pdf\n",
      "225 8.237499332999505 ./chunks/chunk_92_Lecture-13-Columbia.pdf\n",
      "230 8.330287833000511 ./chunks/chunk_97_Lecture-13-Columbia.pdf\n",
      "235 8.31084012500014 ./chunks/chunk_102_Lecture-13-Columbia.pdf\n",
      "240 8.75368141600029 ./chunks/chunk_107_Lecture-13-Columbia.pdf\n",
      "245 7.9195339589996365 ./chunks/chunk_3_Lecture-5-columbia-Fall2024.pdf\n",
      "250 7.279840749999494 ./chunks/chunk_8_Lecture-5-columbia-Fall2024.pdf\n",
      "255 7.964158249999855 ./chunks/chunk_13_Lecture-5-columbia-Fall2024.pdf\n",
      "260 7.67915075000019 ./chunks/chunk_18_Lecture-5-columbia-Fall2024.pdf\n",
      "265 7.593029124999703 ./chunks/chunk_23_Lecture-5-columbia-Fall2024.pdf\n",
      "270 7.654824750000444 ./chunks/chunk_28_Lecture-5-columbia-Fall2024.pdf\n",
      "275 7.408023332999619 ./chunks/chunk_33_Lecture-5-columbia-Fall2024.pdf\n",
      "280 7.650419833000342 ./chunks/chunk_38_Lecture-5-columbia-Fall2024.pdf\n",
      "285 7.761835332999908 ./chunks/chunk_43_Lecture-5-columbia-Fall2024.pdf\n",
      "290 8.191603917000066 ./chunks/chunk_4_Lecture-7-Columbia.pdf\n",
      "295 9.278614374999961 ./chunks/chunk_9_Lecture-7-Columbia.pdf\n",
      "300 8.957823749999989 ./chunks/chunk_14_Lecture-7-Columbia.pdf\n",
      "305 8.682208458000787 ./chunks/chunk_19_Lecture-7-Columbia.pdf\n",
      "310 8.939435625000442 ./chunks/chunk_24_Lecture-7-Columbia.pdf\n",
      "315 8.399405582999862 ./chunks/chunk_29_Lecture-7-Columbia.pdf\n",
      "320 8.849013416999696 ./chunks/chunk_34_Lecture-7-Columbia.pdf\n",
      "325 8.45350845899975 ./chunks/chunk_39_Lecture-7-Columbia.pdf\n",
      "330 8.78551137499926 ./chunks/chunk_44_Lecture-7-Columbia.pdf\n",
      "335 9.074276291000388 ./chunks/chunk_49_Lecture-7-Columbia.pdf\n",
      "340 8.83377904200006 ./chunks/chunk_54_Lecture-7-Columbia.pdf\n",
      "345 8.709281207999993 ./chunks/chunk_59_Lecture-7-Columbia.pdf\n",
      "350 8.70278800000051 ./chunks/chunk_64_Lecture-7-Columbia.pdf\n",
      "355 7.782674582999789 ./chunks/chunk_69_Lecture-7-Columbia.pdf\n",
      "360 7.945757624999715 ./chunks/chunk_5_Lecture-3-Columbia (1).pdf\n",
      "365 9.017627958000048 ./chunks/chunk_10_Lecture-3-Columbia (1).pdf\n",
      "370 8.849826124999709 ./chunks/chunk_15_Lecture-3-Columbia (1).pdf\n",
      "375 8.68846129099984 ./chunks/chunk_20_Lecture-3-Columbia (1).pdf\n",
      "380 8.775227000000086 ./chunks/chunk_25_Lecture-3-Columbia (1).pdf\n",
      "385 7.722368167000241 ./chunks/chunk_30_Lecture-3-Columbia (1).pdf\n",
      "390 7.860786915999597 ./chunks/chunk_35_Lecture-3-Columbia (1).pdf\n",
      "395 8.501044999999976 ./chunks/chunk_40_Lecture-3-Columbia (1).pdf\n",
      "400 8.740583500000866 ./chunks/chunk_45_Lecture-3-Columbia (1).pdf\n",
      "405 9.020848333000686 ./chunks/chunk_50_Lecture-3-Columbia (1).pdf\n",
      "410 8.964991791000102 ./chunks/chunk_55_Lecture-3-Columbia (1).pdf\n",
      "415 8.706264833000205 ./chunks/chunk_60_Lecture-3-Columbia (1).pdf\n",
      "420 8.27922204099923 ./chunks/chunk_65_Lecture-3-Columbia (1).pdf\n",
      "425 9.838630708999517 ./chunks/chunk_70_Lecture-3-Columbia (1).pdf\n",
      "430 9.201253500000348 ./chunks/chunk_75_Lecture-3-Columbia (1).pdf\n",
      "435 7.668966584000373 ./chunks/chunk_80_Lecture-3-Columbia (1).pdf\n",
      "440 7.781664375000219 ./chunks/chunk_5_Lecture-2-columbia-Fall2024.pdf\n",
      "445 7.8346565419997205 ./chunks/chunk_10_Lecture-2-columbia-Fall2024.pdf\n",
      "450 7.589046707999842 ./chunks/chunk_15_Lecture-2-columbia-Fall2024.pdf\n",
      "455 7.356198208999558 ./chunks/chunk_20_Lecture-2-columbia-Fall2024.pdf\n",
      "460 7.774766458000158 ./chunks/chunk_25_Lecture-2-columbia-Fall2024.pdf\n",
      "465 8.031287833000533 ./chunks/chunk_30_Lecture-2-columbia-Fall2024.pdf\n",
      "470 8.357353708999653 ./chunks/chunk_35_Lecture-2-columbia-Fall2024.pdf\n",
      "475 9.569471917000556 ./chunks/chunk_40_Lecture-2-columbia-Fall2024.pdf\n",
      "480 7.439694833999965 ./chunks/chunk_45_Lecture-2-columbia-Fall2024.pdf\n",
      "485 7.687130541999977 ./chunks/chunk_50_Lecture-2-columbia-Fall2024.pdf\n",
      "490 8.185709874999702 ./chunks/chunk_55_Lecture-2-columbia-Fall2024.pdf\n",
      "495 7.911954541999876 ./chunks/chunk_60_Lecture-2-columbia-Fall2024.pdf\n",
      "500 8.784260291999999 ./chunks/chunk_65_Lecture-2-columbia-Fall2024.pdf\n",
      "505 7.441585542000212 ./chunks/chunk_70_Lecture-2-columbia-Fall2024.pdf\n",
      "510 8.117459291999694 ./chunks/chunk_75_Lecture-2-columbia-Fall2024.pdf\n",
      "515 7.629976332999831 ./chunks/chunk_80_Lecture-2-columbia-Fall2024.pdf\n",
      "520 8.041072209000049 ./chunks/chunk_85_Lecture-2-columbia-Fall2024.pdf\n",
      "525 7.595909167000173 ./chunks/chunk_1_Lecture-9-Columbia.pdf\n",
      "530 7.698650000000271 ./chunks/chunk_6_Lecture-9-Columbia.pdf\n",
      "535 7.467916333000176 ./chunks/chunk_11_Lecture-9-Columbia.pdf\n",
      "540 7.911277707999943 ./chunks/chunk_16_Lecture-9-Columbia.pdf\n",
      "545 7.580332708000242 ./chunks/chunk_21_Lecture-9-Columbia.pdf\n",
      "550 7.750810916999399 ./chunks/chunk_26_Lecture-9-Columbia.pdf\n",
      "555 6.80767829099932 ./chunks/chunk_31_Lecture-9-Columbia.pdf\n",
      "560 7.032660541000041 ./chunks/chunk_36_Lecture-9-Columbia.pdf\n",
      "565 8.225823832999595 ./chunks/chunk_41_Lecture-9-Columbia.pdf\n",
      "570 7.221644125000239 ./chunks/chunk_46_Lecture-9-Columbia.pdf\n",
      "575 7.746955707999405 ./chunks/chunk_51_Lecture-9-Columbia.pdf\n",
      "580 8.89356320800016 ./chunks/chunk_56_Lecture-9-Columbia.pdf\n",
      "585 8.760759707999568 ./chunks/chunk_61_Lecture-9-Columbia.pdf\n",
      "590 7.985754457999974 ./chunks/chunk_66_Lecture-9-Columbia.pdf\n",
      "595 7.885314541999833 ./chunks/chunk_71_Lecture-9-Columbia.pdf\n",
      "600 8.285354124999685 ./chunks/chunk_76_Lecture-9-Columbia.pdf\n",
      "605 7.432501375000356 ./chunks/chunk_81_Lecture-9-Columbia.pdf\n",
      "610 8.597793083000397 ./chunks/chunk_1_Lecture-11-columbia.pdf\n",
      "615 7.085838958999375 ./chunks/chunk_6_Lecture-11-columbia.pdf\n",
      "620 7.750360541999726 ./chunks/chunk_11_Lecture-11-columbia.pdf\n",
      "625 8.704311041999972 ./chunks/chunk_16_Lecture-11-columbia.pdf\n",
      "630 8.437389249999796 ./chunks/chunk_21_Lecture-11-columbia.pdf\n",
      "635 8.01620370799992 ./chunks/chunk_26_Lecture-11-columbia.pdf\n",
      "640 8.339264958000058 ./chunks/chunk_31_Lecture-11-columbia.pdf\n",
      "645 7.960805708999942 ./chunks/chunk_36_Lecture-11-columbia.pdf\n",
      "650 7.983526250000068 ./chunks/chunk_41_Lecture-11-columbia.pdf\n",
      "655 7.528581624999788 ./chunks/chunk_1_Lecture-6-columbia-Fall2024.pdf\n",
      "660 7.995284208000157 ./chunks/chunk_6_Lecture-6-columbia-Fall2024.pdf\n",
      "665 7.4731590829997 ./chunks/chunk_11_Lecture-6-columbia-Fall2024.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "670 6.929717415999221 ./chunks/chunk_16_Lecture-6-columbia-Fall2024.pdf\n",
      "675 7.669259667000006 ./chunks/chunk_21_Lecture-6-columbia-Fall2024.pdf\n",
      "680 7.963793916999748 ./chunks/chunk_26_Lecture-6-columbia-Fall2024.pdf\n",
      "685 7.476365084000463 ./chunks/chunk_4_Lecture-10-Columbia.pdf\n",
      "690 8.1687207089999 ./chunks/chunk_9_Lecture-10-Columbia.pdf\n",
      "695 8.90650420899965 ./chunks/chunk_14_Lecture-10-Columbia.pdf\n",
      "700 9.140342749999945 ./chunks/chunk_19_Lecture-10-Columbia.pdf\n",
      "705 7.98733508299938 ./chunks/chunk_24_Lecture-10-Columbia.pdf\n",
      "710 8.115165457999865 ./chunks/chunk_29_Lecture-10-Columbia.pdf\n",
      "715 8.156138875000579 ./chunks/chunk_34_Lecture-10-Columbia.pdf\n",
      "720 9.232960582999112 ./chunks/chunk_39_Lecture-10-Columbia.pdf\n",
      "725 8.515497958000196 ./chunks/chunk_44_Lecture-10-Columbia.pdf\n",
      "730 7.679936417000135 ./chunks/chunk_49_Lecture-10-Columbia.pdf\n",
      "735 7.841302666000047 ./chunks/chunk_54_Lecture-10-Columbia.pdf\n",
      "740 8.02238770799977 ./chunks/chunk_59_Lecture-10-Columbia.pdf\n",
      "745 7.95550374999948 ./chunks/chunk_64_Lecture-10-Columbia.pdf\n",
      "750 8.129068791000464 ./chunks/chunk_69_Lecture-10-Columbia.pdf\n",
      "755 8.778868874999716 ./chunks/chunk_74_Lecture-10-Columbia.pdf\n",
      "760 7.308207125000081 ./chunks/chunk_79_Lecture-10-Columbia.pdf\n",
      "765 7.450056874999973 ./chunks/chunk_84_Lecture-10-Columbia.pdf\n",
      "770 8.137261249999938 ./chunks/chunk_89_Lecture-10-Columbia.pdf\n",
      "775 7.93935566699929 ./chunks/chunk_94_Lecture-10-Columbia.pdf\n",
      "780 7.570794291999846 ./chunks/chunk_99_Lecture-10-Columbia.pdf\n",
      "785 7.668086333000247 ./chunks/chunk_104_Lecture-10-Columbia.pdf\n",
      "790 7.2911123750000115 ./chunks/chunk_109_Lecture-10-Columbia.pdf\n",
      "795 7.571943208999983 ./chunks/chunk_4_Lecture-4-columbia-Fall2024.pdf\n",
      "800 8.164453834000597 ./chunks/chunk_9_Lecture-4-columbia-Fall2024.pdf\n",
      "805 7.55943654100065 ./chunks/chunk_14_Lecture-4-columbia-Fall2024.pdf\n",
      "810 10.460296374999416 ./chunks/chunk_19_Lecture-4-columbia-Fall2024.pdf\n",
      "815 8.346888082999612 ./chunks/chunk_24_Lecture-4-columbia-Fall2024.pdf\n",
      "820 7.89074837499993 ./chunks/chunk_29_Lecture-4-columbia-Fall2024.pdf\n",
      "825 8.620286416000454 ./chunks/chunk_34_Lecture-4-columbia-Fall2024.pdf\n",
      "830 7.123980625000513 ./chunks/chunk_39_Lecture-4-columbia-Fall2024.pdf\n",
      "835 7.343548041999384 ./chunks/chunk_44_Lecture-4-columbia-Fall2024.pdf\n",
      "840 7.287329791999582 ./chunks/chunk_49_Lecture-4-columbia-Fall2024.pdf\n",
      "845 7.550609832999726 ./chunks/chunk_54_Lecture-4-columbia-Fall2024.pdf\n",
      "850 8.078799249999975 ./chunks/chunk_59_Lecture-4-columbia-Fall2024.pdf\n",
      "855 7.282098333000249 ./chunks/chunk_64_Lecture-4-columbia-Fall2024.pdf\n",
      "860 7.505362832999708 ./chunks/chunk_69_Lecture-4-columbia-Fall2024.pdf\n",
      "865 7.529766540999844 ./chunks/chunk_74_Lecture-4-columbia-Fall2024.pdf\n",
      "870 9.03695824999977 ./chunks/chunk_79_Lecture-4-columbia-Fall2024.pdf\n",
      "875 8.04511787499996 ./chunks/chunk_5_Lecture-8-Columbia.pdf\n",
      "880 7.8007027499998 ./chunks/chunk_10_Lecture-8-Columbia.pdf\n",
      "885 8.117723082999873 ./chunks/chunk_15_Lecture-8-Columbia.pdf\n",
      "890 8.800097041999834 ./chunks/chunk_20_Lecture-8-Columbia.pdf\n",
      "895 9.241167666000365 ./chunks/chunk_25_Lecture-8-Columbia.pdf\n",
      "900 7.645130375000008 ./chunks/chunk_30_Lecture-8-Columbia.pdf\n",
      "905 7.796405208000579 ./chunks/chunk_35_Lecture-8-Columbia.pdf\n",
      "910 8.15077137499975 ./chunks/chunk_40_Lecture-8-Columbia.pdf\n",
      "915 8.70919533400047 ./chunks/chunk_45_Lecture-8-Columbia.pdf\n",
      "920 9.176570124999671 ./chunks/chunk_50_Lecture-8-Columbia.pdf\n",
      "925 8.926850458000445 ./chunks/chunk_55_Lecture-8-Columbia.pdf\n",
      "930 8.929297542000313 ./chunks/chunk_60_Lecture-8-Columbia.pdf\n",
      "935 8.783865000000333 ./chunks/chunk_65_Lecture-8-Columbia.pdf\n",
      "940 9.315037708999625 ./chunks/chunk_70_Lecture-8-Columbia.pdf\n",
      "945 11.75281829100004 ./chunks/chunk_75_Lecture-8-Columbia.pdf\n"
     ]
    }
   ],
   "source": [
    "all_processed_chunks = list(all_data.keys())\n",
    "start = timeit.default_timer()\n",
    "for i,chunk in enumerate(all_chunks):\n",
    "    if chunk not in all_processed_chunks:\n",
    "        text, links = get_document_extraction(chunk)\n",
    "        all_data[chunk] = {'text':text,'links':links}\n",
    "        if i%5 ==0:\n",
    "            end = timeit.default_timer()\n",
    "            print(i, end-start, chunk)\n",
    "            start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "a6ae10c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_cleaned = {}\n",
    "for key,value in all_data.items():\n",
    "    if len(value['links'])>0:\n",
    "        all_data_cleaned[key] = {'text':value['text'],'links':extract_text_links(value['text'])}\n",
    "    else:\n",
    "        all_data_cleaned[key] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "77951cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Specify the file name of the JSON file\n",
    "# file_name = \"data_from_presentations.json\"\n",
    "\n",
    "# # Load the JSON file\n",
    "# with open(file_name, \"r\") as json_file:\n",
    "#     data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "f7849ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_processed_chunks = list(all_data_cleaned.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397b337",
   "metadata": {},
   "source": [
    "<h1>3. Aggregating all links from class presentations and HW</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "4b701340",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_links = []\n",
    "for extracted_data in list(list(all_data_cleaned.values())):\n",
    "    all_links = all_links + extracted_data['links']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ae9cadbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_extracted_data = {key:value for key, value in extracted_data.items() if len(value)>=1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ff0f6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files_to_extract_data_from = os.listdir('./HWs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "5f99c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hw_chunks = []\n",
    "for file_name in all_files_to_extract_data_from:\n",
    "    file_directory = \"./HWs\"\n",
    "    pdf_path = os.path.join(file_directory, file_name)\n",
    "    chunks = split_pdf(pdf_path,file_name, max_pages = 15)\n",
    "    all_hw_chunks = all_hw_chunks + chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "f8112a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_hw_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "dfc60108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.847637875000146 ./chunks/chunk_1_HW4-PDF.pdf\n"
     ]
    }
   ],
   "source": [
    "all_processed_chunks = list(all_hw_data.keys())\n",
    "start = timeit.default_timer()\n",
    "for i,chunk in enumerate(all_hw_chunks):\n",
    "    if chunk not in all_processed_chunks:\n",
    "        text, links = get_document_extraction(chunk)\n",
    "        all_hw_data[chunk] = {'text':text,'links':links}\n",
    "        if i%5 ==0:\n",
    "            end = timeit.default_timer()\n",
    "            print(i, end-start, chunk)\n",
    "            start = timeit.default_timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "aac9f2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hw_links = []\n",
    "for extracted_data in list(all_hw_data.values()):\n",
    "    all_hw_links = all_hw_links + extracted_data['links']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab590e8",
   "metadata": {},
   "source": [
    "<h1>4. Finding new relevant links, by mining topics from the syllabus and finding relevant blog posts links</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "3566e385",
   "metadata": {},
   "outputs": [],
   "source": [
    "text,links = get_document_extraction('./Syllabus/Fall 2024 Syllabus-columbia-110524.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "4e9ed1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    start = timeit.default_timer()\n",
    "    all_messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"I am currently taking a class called Introduction to Deep Learning and LLM based Generative AI Systems\"},\n",
    "    {\"role\": \"user\", \"content\": f\"I want you to extract all topics I will learn from this class: {text}.\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Please make sure to only extract topics related to Machine Learning, Large Language Models, Computer Science, and Software Engineering topics\"},\n",
    "    {\"role\": \"user\", \"content\": \"Please format the output as a list topics. Here is an example: ['model parallelism','Devops principles in machine learning']\"},\n",
    "    {\"role\": \"user\", \"content\": f\"Please return nothing else other than a string version of the list\"}\n",
    "    ]\n",
    "    response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-4o\",\n",
    "    max_tokens = 8000,\n",
    "    messages=all_messages\n",
    "    )\n",
    "    course_topics = response['choices'][0]['message']['content']\n",
    "    course_topics_cleaned = clean_q_a_string_json(course_topics)\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5f4f0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_google_search_results_html(response):\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Parse the JSON response\n",
    "        html_content = data.get(\"body\", \"\")  # Get the raw HTML from the \"body\" key\n",
    "        # Parse the HTML content using BeautifulSoup\n",
    "        soup = BeautifulSoup(html_content, \"lxml\")\n",
    "        # Dictionary to hold the results\n",
    "        results_dict = {}\n",
    "        # Loop through search result elements - adjust as necessary\n",
    "        for result in soup.find_all(\"div\", class_=\"g\"):  # \"g\" is the common class for Google search results\n",
    "            link_tag = result.find(\"a\", href=True)\n",
    "            title_tag = result.find(\"h3\")\n",
    "            if link_tag and title_tag:\n",
    "                url = link_tag[\"href\"]\n",
    "                title = title_tag.get_text()\n",
    "                results_dict[url] = title\n",
    "        return results_dict\n",
    "    else:\n",
    "        print(f\"Error: Received status code {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "93f066a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_google_search_results(query,api_token = \"0fbec085971dc1ca50b111c6433d49bd989a57b81344bfb508754d9687d19efa\"):\n",
    "    search_url = f\"https://www.google.com/search?q={query.replace(' ', '+')}\"\n",
    "    url = \"https://api.brightdata.com/request\"\n",
    "    payload = {\n",
    "        \"zone\": \"serp_api3\",  # Replace with your actual zone if different\n",
    "        \"url\": search_url,\n",
    "        \"format\": \"json\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"Authorization\": f\"Bearer {api_token}\"\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.post(url, headers=headers, data=json.dumps(payload))\n",
    "    all_search_results = parse_google_search_results_html(response)\n",
    "    return all_search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "8efab0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanitize_query_string(query):\n",
    "    # Normalize the query to decompose special characters\n",
    "    normalized = unicodedata.normalize(\"NFD\", query)\n",
    "    # Encode to ASCII, ignoring any non-ASCII characters\n",
    "    ascii_encoded = normalized.encode(\"ascii\", \"ignore\").decode(\"utf-8\")\n",
    "    # URL-encode the sanitized query string\n",
    "    return urllib.parse.quote_plus(ascii_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "18d3b8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"Blog post explaining {course_topics_cleaned[1]} in Deep Learning, Machine Learning, Computer Science, or Software Engineering \"\n",
    "linkedin_url = None\n",
    "#     print(query)\n",
    "sanitized_query = sanitize_query_string(query)\n",
    "results = get_google_search_results(sanitized_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "5c525c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.8749121250002645 5\n",
      "5 17.543654875000357 29\n",
      "10 31.217416375002358 54\n",
      "15 63.02728124999703 79\n",
      "20 73.60367716699693 100\n",
      "25 88.57625995900162 123\n",
      "30 99.52590387500095 148\n",
      "35 110.69694012500258 171\n",
      "40 139.45502395900257 195\n",
      "45 155.12103224999737 215\n",
      "50 164.55748754199885 239\n",
      "55 179.83256741699734 262\n",
      "60 190.92883874999825 283\n",
      "65 202.32500008399802 305\n",
      "70 212.8582381669985 329\n",
      "75 225.31525770900043 354\n",
      "80 237.91018229199835 373\n",
      "85 250.4848908749991 391\n",
      "90 260.39152995900076 415\n",
      "95 274.1067696250029 437\n",
      "100 283.8554647089986 459\n",
      "105 298.89148462499725 480\n"
     ]
    }
   ],
   "source": [
    "all_results = {}\n",
    "start = timeit.default_timer()\n",
    "for i,topic in enumerate(course_topics_cleaned):\n",
    "    query = f\"Blog post explaining {topic} in Deep Learning, Machine Learning, Computer Science, or Software Engineering \"\n",
    "    linkedin_url = None\n",
    "    #     print(query)\n",
    "    sanitized_query = sanitize_query_string(query)\n",
    "    results = get_google_search_results(sanitized_query)\n",
    "    num_articles= 0\n",
    "    for key,value in results.items():\n",
    "        if num_articles<=4:\n",
    "            all_results[key] = value\n",
    "            num_articles+=1\n",
    "        else:\n",
    "            break\n",
    "    end = timeit.default_timer()\n",
    "    if i%5 ==0:\n",
    "        print(i,end-start,len(list(all_results.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "23df6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_google_blog_links = list(all_results.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f8016f3",
   "metadata": {},
   "source": [
    "<h1>5. Extracting all text from links</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "f555eb5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://github.com/ray-project/llm-numbers#1-mb-gpu-memory-required-for-1-token-of-output-with-a-13b-parameter-model\n",
      "Processing: https://arxiv.org/abs/2205.14135\n",
      "Processing: https://ai.stanford.edu/blog/longer-sequencesnext-leap-ai/\n",
      "Processing: https://github.com/vllm-project/vllm\n",
      "Processing: https://vllm.ai\n",
      "Processing: https://arxiv.org/abs/2309.06180\n",
      "Processing: https://discord.gg/jz7wjKhh6g\n",
      "Processing: https://docs.nvidia.com/datacenter/tesla/mig-userguide/index.html\n",
      "Processing: https://huggingface.co/blog/trl-peft\n",
      "Processing: https://arxiv.org/pdf/2202.05924\n",
      "Processing: https://splab.sdu.edu.cn/G\n",
      "Processing: https://research.google/blog/pathways-languagemodel-palm-scaling-to-540-billion-parameters-for-breakthrough-performance/\n",
      "Processing: https://arxiv.org/pdf/2202.05924\n",
      "Processing: https://www.youtube.com/watch?v=EnJ7qX9fkcU\n",
      "Processing: https://jvns.ca/blog/2016/10/10/what-even-is-a-container/\n",
      "Processing: https://kubernetes.io/\n",
      "Processing: https://cloud.google.com/kubernetesengine/\n",
      "Processing: https://www.alibabacloud.com/product/kubernetes\n",
      "Processing: https://aws.amazon.com/eks/\n",
      "Processing: https://azure.microsoft.com/enus/services/kubernetes-service/\n",
      "Processing: https://github.com/IBM/FfDL\n",
      "Processing: https://www.ibm.com/products/watson-studio\n",
      "Processing: https://aws.amazon.com/sagemaker\n",
      "Processing: https://azure.com/ml\n",
      "Processing: https://cloud.google.com/vertex-ai/\n",
      "Processing: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html\n",
      "Processing: https://arxiv.org/pdf/2202.05924\n",
      "Processing: https://website-754fwhahs-humanloopml.vercel.app/blog/open_ai_talk\n",
      "Processing: https://arxiv.org/pdf/2202.05924\n",
      "Processing: https://splab.sdu.edu.cn/GPT3.pdf\n",
      "Processing: https://research.google/blog/pathw\n",
      "Processing: https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/\n",
      "Processing: https://lambdalabs.com/blog/2080-ti-deep-learning-benchmarks/\n",
      "Processing: https://docs.aws.amazon.com/sagemaker/latest/dg/model-parallel-intro.html\n",
      "Processing: https://arxiv.org/pdf/1811.05233.pdf\n",
      "Processing: https://cloud.google.com/tpu/docs/systemarchitecture\n",
      "Processing: https://medium.com/mlreview/a-guide-to-receptive-fieldarithmetic-for-convolutional-neural-networks-e0f514068807\n",
      "Processing: https://github.com/bitsandbytes-foundation/bitsandbytes\n",
      "Processing: https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory\n",
      "Processing: https://github.com/bitsandbytes-foundation/bitsandbytes\n",
      "Processing: https://huggingface.co/docs/transformers/v4.20.1/en/perf_train_gpu_one#anatomy-of-models-memory\n",
      "Processing: https://arxiv.org/pdf/2005.14165\n",
      "Processing: https://gluebenchmark.com/leaderboard\n",
      "Processing: https://super.gluebenchmark.com/leaderboard/\n",
      "Processing: https://crfm.stanford.edu/helm/\n",
      "Processing: https://crfm.stanford.edu/helm/\n",
      "Processing: https://www.anyscale.com/blog/reproducible-performance-metrics-for-llm-inference\n",
      "Processing: https://github.com/ray-project/LLMPerf\n",
      "Processing: https://github.com/ray-project/llmperf-leaderboard\n",
      "Processing: https://github.com/ray-project/llmperf-leaderboard\n",
      "Processing: https://www.kubeflow.org/docs/about/kubeflow/\n",
      "Processing: https://www.kubeflow.org/docs/pipelines/pipelines-quickstart/\n",
      "Processing: https://www.kubeflow.org/docs/pi\n",
      "Processing: https://www.kubeflow.org/docs/pipelines/overview/concepts/comp\n",
      "Processing: https://www.kubeflow.org/docs/pipelines/refe\n",
      "Processing: https://mlcommons.org\n",
      "Processing: https://mlcommons.org/benchmarks/storage/\n",
      "Processing: https://github.com/bigscience-workshop/promptsource/blob/main/promptsource/templates/amazon_polarity/templates.yaml\n",
      "Processing: https://huggingface.co/datasets/samsum,\n",
      "Processing: https://github.com/google-research/FLAN/blob/2c79a31/flan/v2/templates.py\n",
      "Processing: https://huggingface.co/datasets/knkarthick/dialogsum/viewer/knkarthick--dialo\n",
      "Processing: https://arxiv.org/pdf/1806.09055.pdf\n",
      "Processing: http://onnx.ai\n",
      "Processing: http://onnx.ai\n",
      "Processing: http://onnx.ai/supported-tools\n",
      "Processing: https://github.com/onnx/tutorials\n",
      "Processing: https://github.com/onnx/models\n",
      "Processing: http://onnx.ai/supported-tools\n",
      "Processing: https://github.com/microsoft/onnxruntime\n",
      "Processing: https://github.com/huggingface/notebooks/blob/main/examples/onnx\n",
      "Processing: https://github.com/tensorflow/models\n",
      "Processing: https://github.com/pytorch/vision\n",
      "Processing: https://www.restack.io/p/retrieval-augmented-generation-answer-rag-vs-semantic-cat-ai\n",
      "Processing: https://www.geeksforgeeks.org/keywordsearching-algorithms-for-search-engines/\n",
      "Processing: https://en.wikipedia.org/wiki/Okapi_BM25\n",
      "Processing: https://drive.google.com/file/d/1UCb_ED3anGlfUvqm19ZKvVdBTBJb4KM/view?usp=sharing\n",
      "Processing: https://api.open-meteo.com/v1/forecast\"\n"
     ]
    }
   ],
   "source": [
    "extracted_data = process_links(all_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "448c7ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://dustinstansbury.github.io/theclevermachine/bias-variance-tradeoff.\n",
      "Processing: https://arxiv.org/pdf/1611.03530.pdf.\n",
      "Processing: https://arxiv.org/abs/1506.01186.\n",
      "Processing: https://arxiv.org/pdf/1611.03530.pdf\n",
      "Processing: https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutionalneural-networks.pdf\n",
      "Processing: https://arxiv.org/pdf/1409.1556.pdf\n",
      "Processing: https://arxiv.org/pdf/1409.4842.pdf\n",
      "Processing: https://github.com/qfgaohao/pytorch-ssd\n",
      "Processing: https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html\n",
      "Processing: https://github.com/onnx/tutorials/blob/master/tutorials/OnnxRuntimeServerSSDModel.ipynb\n",
      "Processing: https://storage.googleapis.com/openimages/web/index.html\n",
      "Processing: http://host.robots.ox.ac.uk/pascal/VOC/voc2007/\n",
      "Processing: https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
      "Processing: https://cs231n.github.io/transfer-learning/\n",
      "Processing: http://host.robots.ox.ac.uk/pascal/VOC/voc2007/\n"
     ]
    }
   ],
   "source": [
    "extracted_hw_data = process_links(all_hw_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "5ee1936e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://arize.com/blog/understanding-bias-in-ml-models/\n",
      "Processing: https://medium.com/@sruthy.sn91/addressing-bias-in-machine-learning-techniques-and-ethical-considerations-fe9d9532d657\n",
      "Processing: https://www.scalablepath.com/machine-learning/bias-machine-learning\n",
      "Processing: https://www.wovenware.com/blog/2020/07/3-bias-machine-learning/\n",
      "Processing: https://www.encora.com/insights/a-short-discussion-on-bias-in-machine-learning\n",
      "Processing: https://www.simplilearn.com/tutorials/machine-learning-tutorial/bias-and-variance\n",
      "Processing: https://www.bmc.com/blogs/bias-variance-machine-learning/\n",
      "Processing: https://data-science-blog.com/blog/2020/11/02/bias-and-variance-in-machine-learning/\n",
      "Processing: http://varianceexplained.org/r/ds-ml-ai/\n",
      "Processing: https://towardsai.net/p/l/mastering-the-bias-variance-dilemma-a-guide-for-machine-learning-practitioners\n",
      "Processing: http://research.google/blog/a-new-lens-on-understanding-generalization-in-deep-learning/\n",
      "Processing: https://dominicm73.blogspot.com/2021/03/regularization-and-generalization-in.html\n",
      "Processing: https://magnimindacademy.com/blog/what-is-generalization-in-machine-learning/\n",
      "Processing: https://www.reddit.com/r/MachineLearning/comments/8mpxmm/d_what_do_we_currently_know_about_generalization/\n",
      "Processing: https://queentechsolutions.net/blog/software/software-engineering-vs-machine-learning/\n",
      "Processing: https://www.simplilearn.com/tutorials/machine-learning-tutorial/regularization-in-machine-learning\n",
      "Processing: https://www.sprintzeal.com/blog/machine-learning-regularization\n",
      "Processing: https://www.geeksforgeeks.org/regularization-in-machine-learning/\n",
      "Processing: https://www.analyticsvidhya.com/blog/2018/04/fundamentals-deep-learning-regularization-techniques/\n",
      "Processing: https://levity.ai/blog/difference-machine-learning-deep-learning\n",
      "Processing: https://www.zendesk.com/blog/machine-learning-and-deep-learning/\n",
      "Processing: https://sunscrapers.com/blog/machine-learning-vs-deep-learning/\n",
      "Processing: https://kareemai.com/blog/posts/ds_and_algo/master_ds.html\n",
      "Processing: https://www.netguru.com/blog/machine-learning-vs-deep-learning\n",
      "Processing: https://karpathy.medium.com/yes-you-should-understand-backprop-e2f06eab496b\n",
      "Processing: https://serokell.io/blog/understanding-backpropagation\n",
      "Processing: https://medium.com/@tam.tamanna18/backpropagation-in-neural-networks-a-comprehensive-guide-3d36151b8fb4\n",
      "Processing: https://vinodsblog.com/2019/02/17/deep-learning-backpropagation-algorithm-basics/\n",
      "Processing: https://www.reddit.com/r/MachineLearning/comments/9ddg3y/d_what_do_you_think_is_the_best_way_to_understand/\n",
      "Processing: https://towardsdatascience.com/gradient-descent-a-beginners-guide-fa0b5d0a1db8\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/t5pz3z/the_magic_of_machine_learning_gradient_descent/\n",
      "Processing: https://www.datacamp.com/tutorial/tutorial-gradient-descent\n",
      "Processing: https://medium.com/quantyca/gradient-descent-in-deep-learning-b1077b89af81\n",
      "Processing: https://graphite-note.com/understanding-gradient-descent/\n",
      "Processing: https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html\n",
      "Processing: https://www.analyticsvidhya.com/blog/2020/01/fundamentals-deep-learning-activation-functions-when-to-use-them/\n",
      "Processing: https://towardsdatascience.com/everything-you-need-to-know-about-activation-functions-in-deep-learning-models-84ba9f82c253\n",
      "Processing: https://blog.roboflow.com/activation-function-computer-vision/\n",
      "Processing: https://medium.com/@shaomukherjee/understanding-activation-functions-a-comprehensive-overview-d3e7b0cd2e39\n",
      "Processing: https://medium.com/@shivansh20128/what-are-vanishing-gradients-and-exploding-gradients-54d9e32c9b99\n",
      "Processing: https://neptune.ai/blog/vanishing-and-exploding-gradients-debugging-monitoring-fixing\n",
      "Processing: https://www.geeksforgeeks.org/vanishing-and-exploding-gradients-problems-in-deep-learning/\n",
      "Processing: https://www.analyticsvidhya.com/blog/2021/06/the-challenge-of-vanishing-exploding-gradients-in-deep-neural-networks/\n",
      "Processing: https://programmathically.com/understanding-the-exploding-and-vanishing-gradients-problem/\n",
      "Processing: https://machinelearningmastery.com/weight-initialization-for-deep-learning-neural-networks/\n",
      "Processing: https://medium.com/@akshayhitendrashah/cliches-of-deep-learning-part-i-5206a17c3264\n",
      "Processing: https://medium.com/@juanc.olamendy/weight-initialization-for-deep-learning-neural-networks-6047cbe27297\n",
      "Processing: https://www.linkedin.com/advice/0/what-best-weight-initialization-techniques-deep-3xinf\n",
      "Processing: https://www.reddit.com/r/deeplearning/comments/1evwa3d/why_do_we_initialize_the_neural_networks_randomly/\n",
      "Processing: https://www.mygreatlearning.com/blog/understanding-learning-rate-in-machine-learning/\n",
      "Processing: https://www.machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/\n",
      "Processing: https://medium.com/@ach.chathuranga/the-art-and-science-of-learning-rates-in-deep-learning-826fe4e85b07\n",
      "Processing: https://spotintelligence.com/2024/02/19/learning-rate-machine-learning/\n",
      "Processing: https://towardsdatascience.com/deep-learning-personal-notes-part-1-lesson-2-8946fe970b95\n",
      "Processing: https://medium.com/@juanc.olamendy/real-world-ml-understanding-batch-size-train-faster-and-better-deep-learning-models-2b24c353e292\n",
      "Processing: https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa\n",
      "Processing: https://www.linkedin.com/pulse/power-batch-size-comprehensive-guide-gradient-descent-juan-carlos-dg5de\n",
      "Processing: https://www.bacancytechnology.com/qanda/qa-automation/batch-size-in-background-of-deep-reinforcement-learning\n",
      "Processing: https://www.sabrepc.com/blog/Deep-Learning-and-AI/Epochs-Batch-Size-Iterations?srsltid=AfmBOoqiQ5cmo_fDNWZLv8VLRlftrCmcxef2e2vRDCJfiSsNb9XfH4I6\n",
      "Processing: https://medium.com/@piyushkashyap045/understanding-sgd-with-momentum-in-deep-learning-a-beginner-friendly-guide-0252ede605b4\n",
      "Processing: https://blog.dailydoseofds.com/p/momentum-explained-visually-and-intuitively\n",
      "Processing: https://karan3-zoh.medium.com/paper-summary-on-the-importance-of-initialization-and-momentum-in-deep-learning-8b8121d21aa9\n",
      "Processing: https://www.digitalocean.com/community/tutorials/intro-to-optimization-momentum-rmsprop-adam\n",
      "Processing: https://stackoverflow.com/questions/56482528/what-is-momentum-in-machine-learning\n",
      "Processing: https://medium.com/@ngneha090/batch-normalization-in-deep-learning-5f200f6f7733\n",
      "Processing: https://medium.com/@utsavraj.ptn04/demystifying-batch-normalization-in-deep-learning-a-beginners-guide-3aa916390875\n",
      "Processing: https://www.analyticsvidhya.com/blog/2021/03/introduction-to-batch-normalization/\n",
      "Processing: https://www.geeksforgeeks.org/what-is-batch-normalization-in-deep-learning/\n",
      "Processing: https://graphite-note.com/the-impact-of-batch-normalization-in-machine-learning/\n",
      "Processing: https://medium.com/@sujathamudadla1213/weight-decay-in-deep-learning-8fb8b5dd825c\n",
      "Processing: https://programmathically.com/weight-decay-in-neural-networks/\n",
      "Processing: https://spotintelligence.com/2024/05/02/weight-decay/\n",
      "Processing: https://towardsdatascience.com/weight-decay-and-its-peculiar-effects-66e0aee3e7b8\n",
      "Processing: https://www.linkedin.com/posts/skphd_why-do-we-need-weight-decay-in-modern-deep-activity-7261978555968831490-R44j\n",
      "Processing: https://medium.com/@utsavraj.ptn04/dropping-the-knowledge-bomb-understanding-dropout-layers-in-deep-learning-0612f517269d\n",
      "Processing: https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
      "Processing: https://www.geeksforgeeks.org/dropout-regularization-in-deep-learning/\n",
      "Processing: https://spotintelligence.com/2023/08/15/dropout-in-neural-network/\n",
      "Processing: https://www.analyticsvidhya.com/blog/2022/08/dropout-regularization-in-deep-learning/\n",
      "Processing: https://medium.com/@juanc.olamendy/real-world-ml-early-stopping-in-deep-learning-a-comprehensive-guide-fabb1e69f8cc\n",
      "Processing: https://www.sabrepc.com/blog/deep-learning-and-ai/what-is-early-stopping-in-deep-learning?srsltid=AfmBOoqWyvvtVwKedR6dHmYPyb0jP7OdzfJOgetD8cbTriNlQ6RC1IqJ\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://cyborgcodes.medium.com/what-is-early-stopping-in-deep-learning-eeb1e710a3cf\n",
      "Processing: https://www.machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/\n",
      "Processing: https://towardsdatascience.com/early-stopping-why-did-your-machine-learning-model-stop-training-c6b1d64e009e\n",
      "Processing: https://insights.daffodilsw.com/blog/what-is-data-augmentation-in-deep-learning\n",
      "Processing: https://aws.amazon.com/what-is/data-augmentation/\n",
      "Processing: https://www.f22labs.com/blogs/what-is-data-augmentation/\n",
      "Processing: https://medium.com/@saiwadotai/the-essential-guide-to-data-augmentation-in-deep-learning-f66e0907cdc8\n",
      "Processing: https://gretel.ai/technical-glossary/what-is-data-augmentation\n",
      "Processing: https://medium.com/udemy-engineering/delivering-ai-ml-products-efficiently-the-single-node-machine-learning-workflow-bad1389410af\n",
      "Processing: https://www.enthought.com/blog/a-beginners-guide-to-deep-learning/\n",
      "Processing: https://medium.com/@Coursesteach/deep-learning-part-1-86757cf5a0c3\n",
      "Processing: https://www.ml4devs.com/articles/machine-learning-intro-for-developers/\n",
      "Processing: https://afmck.in/posts/2023-02-26-parallelism/\n",
      "Processing: https://medium.com/@dnyaneshwalwadkar/harnessing-the-power-of-parallelism-for-faster-deep-learning-model-training-with-tensorflow-a4f0d05718\n",
      "Processing: https://www.blopig.com/blog/2023/10/understanding-gpu-parallelization-in-deep-learning/\n",
      "Processing: https://www.purestorage.com/knowledge/what-is-model-parallelism.html\n",
      "Processing: https://towardsdatascience.com/distributed-parallel-training-data-parallelism-and-model-parallelism-ec2d234e3214\n",
      "Processing: https://towardsdatascience.com/deep-learning-at-scale-parallel-model-training-d7c22904b5a4\n",
      "Processing: https://www.run.ai/blog/parallelism-strategies-for-distributed-training\n",
      "Processing: https://neptune.ai/blog/distributed-training\n",
      "Processing: https://criss-wang.com/post/blogs/mlops/distributed-training/\n",
      "Processing: https://medium.com/@rachittayal7/a-gentle-introduction-to-distributed-training-of-ml-models-81295a7057de\n",
      "Processing: https://medium.com/cracking-the-data-science-interview/datacast-episode-58-deep-learning-meets-distributed-systems-with-jim-dowling-e14e19538059\n",
      "Processing: https://betterprogramming.pub/parallel-and-distributed-training-in-deep-learning-for-beginners-part-1-introduction-612a4534a117\n",
      "Processing: https://d2l.ai/chapter_computational-performance/parameterserver.html\n",
      "Processing: https://shivambharuka.medium.com/deep-learning-a-primer-on-distributed-training-part-1-d0ae0054bb1c\n",
      "Processing: https://medium.com/coinmonks/parameter-server-for-distributed-machine-learning-fd79d99f84c3\n",
      "Processing: https://github.com/Jokeren/Notes/blob/master/Deep%20Learning/Scaling%20Distributed%20Machine%20Learning%20with%20the%20Parameter%20Server.md\n",
      "Processing: https://medium.com/@mpchang17/making-the-leap-from-hardware-to-machine-learning-part-2-eb172c2e9d8e\n",
      "Processing: https://csweb.rice.edu/academics/graduate-programs/online-mcs/blog/computer-science-vs-artificial-intelligence-and-machine-learning\n",
      "Processing: https://engineering.deptagency.com/machine-learning-explain-it-like-im-five-podcast\n",
      "Processing: https://news.ycombinator.com/item?id=30432987\n",
      "Processing: https://buseyaren.medium.com/what-is-a-gpu-are-they-needed-for-deep-learning-94dd4aeb45f6\n",
      "Processing: https://blogs.nvidia.com/blog/why-gpus-are-great-for-ai/\n",
      "Processing: https://www.run.ai/guides/gpu-deep-learning\n",
      "Processing: https://goonline.io/blog/making-the-leap-why-gpus-are-essential-for-machine-learning-and-deep-learning/\n",
      "Processing: https://www.weka.io/learn/glossary/ai-ml/gpus-for-machine-learning/\n",
      "Processing: https://www.digitalocean.com/community/tutorials/understanding-tensor-cores\n",
      "Processing: https://acecloud.ai/resources/blog/cuda-cores-vs-tensor-cores/\n",
      "Processing: https://developer.nvidia.com/blog/optimizing-gpu-performance-tensor-cores/\n",
      "Processing: https://developer.nvidia.com/blog/tag/tensor-cores/\n",
      "Processing: https://stackoverflow.com/questions/47335027/what-is-the-difference-between-cuda-vs-tensor-cores\n",
      "Processing: https://developer.nvidia.com/blog/scaling-deep-learning-training-nccl/\n",
      "Processing: https://medium.com/@akp83540/nvidia-collective-communications-library-nccl-5c325c41df25\n",
      "Processing: https://medium.com/@pranay.janupalli/introduction-to-nccl-communication-operators-the-backbone-of-efficient-distributed-training-d8b4b2f990a6\n",
      "Processing: https://forums.developer.nvidia.com/t/scaling-deep-learning-training-with-nccl/148629\n",
      "Processing: https://www.youtube.com/watch?v=GjbsCzYwh24\n",
      "Processing: https://www.analyticsvidhya.com/blog/2021/05/convolutional-neural-networks-cnn/\n",
      "Processing: https://www.datacamp.com/tutorial/introduction-to-convolutional-neural-networks-cnns\n",
      "Processing: https://medium.com/@tam.tamanna18/exploring-convolutional-neural-networks-architecture-steps-use-cases-and-pros-and-cons-b0d3b7d46c71\n",
      "Processing: https://vinodsblog.com/2018/10/15/everything-you-need-to-know-about-convolutional-neural-networks/\n",
      "Processing: https://www.linkedin.com/pulse/understanding-convolutional-neural-networks-cnns-deep-aritra-pain\n",
      "Processing: https://medium.com/@utsavraj.ptn04/unraveling-the-wonders-of-recurrent-neural-networks-rnns-a-deep-dive-into-sequential-learning-27d5e74344d3\n",
      "Processing: https://vinodsblog.com/2019/01/07/deep-learning-introduction-to-recurrent-neural-networks/\n",
      "Processing: http://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
      "Processing: https://aws.amazon.com/what-is/recurrent-neural-network/\n",
      "Processing: https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9\n",
      "Processing: https://blog.mlreview.com/understanding-lstm-and-its-diagrams-37e2f46f1714\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/e6x22x/a_very_good_blog_post_to_learn_about_lstm_networks/\n",
      "Processing: https://shiyan.medium.com/materials-to-understand-lstm-34387d6454c1\n",
      "Processing: https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\n",
      "Processing: https://www.analyticsvidhya.com/blog/2022/03/an-overview-on-long-short-term-memory-lstm/\n",
      "Processing: https://www.machinelearningmastery.com/what-are-generative-adversarial-networks-gans/\n",
      "Processing: https://www.analyticsvidhya.com/blog/2021/10/an-end-to-end-introduction-to-generative-adversarial-networksgans/\n",
      "Processing: https://viso.ai/deep-learning/generative-adversarial-networks-gan/\n",
      "Processing: https://vinodsblog.com/2018/11/23/generative-adversarial-networks-gans-the-basics-you-need-to-know/\n",
      "Processing: https://www.proxet.com/blog/introduction-to-generative-adversarial-networks\n",
      "Processing: https://www.superannotate.com/blog/diffusion-models\n",
      "Processing: https://encord.com/blog/diffusion-models/\n",
      "Processing: https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction/\n",
      "Processing: https://towardsai.net/p/machine-learning/ai-ml-diffusion-models-a-beginners-guide-to-math-behind-stable-diffusion-and-dall-e\n",
      "Processing: https://www.reddit.com/r/deeplearning/comments/1fw3m3h/resources_to_better_under_diffusion_model/\n",
      "Processing: https://neptune.ai/blog/best-practices-docker-for-machine-learning\n",
      "Processing: https://medium.com/@diogeneswallis/docker-for-machine-learning-abca15eaadc6\n",
      "Processing: https://aws.amazon.com/blogs/opensource/why-use-docker-containers-for-machine-learning-development/\n",
      "Processing: https://www.reddit.com/r/MachineLearning/comments/iq8i4f/d_using_docker_for_ml_development/\n",
      "Processing: https://cnvrg.io/docker-for-machine-learning-and-reproducible-data-science/\n",
      "Processing: https://medium.com/@datasciencewizards/why-do-we-hear-kubernetes-and-machine-learning-together-so-often-e73bc72a278a\n",
      "Processing: https://www.index.dev/blog/kubernetes-for-software-engineers-what-no-one-tells-you-but-you-need-to-know\n",
      "Processing: https://hamel.dev/blog/posts/k8s/\n",
      "Processing: https://medium.com/@somnath.2301/role-of-kubernetes-based-engineering-in-ai-9540b994ff37\n",
      "Processing: https://overcast.blog/mastering-kubernetes-for-machine-learning-ml-ai-in-2024-26f0cb509d81\n",
      "Processing: https://medium.com/@tenyks_blogger/ml-vs-mlops-engineer-key-differences-similarities-43d612bacdd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://cloud.google.com/discover/deep-learning-vs-machine-learning\n",
      "Processing: https://medium.com/@markpalatucci/deep-learning-in-the-cloud-vs-on-premises-machines-d9707ddfec22\n",
      "Processing: https://aws.amazon.com/blogs/machine-learning/\n",
      "Processing: https://aws.amazon.com/what-is/deep-learning/\n",
      "Processing: https://aws.amazon.com/blogs/architecture/lets-architect-learn-about-machine-learning-on-aws/\n",
      "Processing: https://www.whizlabs.com/blog/aws-deep-learning/\n",
      "Processing: https://k21academy.com/amazon-web-services/aws-ml/deep-learning/\n",
      "Processing: https://techcommunity.microsoft.com/tag/software%20engineering?nodeId=board%3AEducatorDeveloperBlog\n",
      "Processing: https://opensource.microsoft.com/blog/topic/deep-learning/\n",
      "Processing: https://learn.microsoft.com/en-us/community/content/get-started-machine-learning\n",
      "Processing: https://blog.acolyer.org/2019/07/08/software-engineering-for-machine-learning/\n",
      "Processing: https://www.microsoft.com/en-us/research/project/deep-program-understanding/\n",
      "Processing: http://research.google/blog/ai-in-software-engineering-at-google-progress-and-the-path-ahead/\n",
      "Processing: https://itcraftapps.com/blog/google-machine-learning/\n",
      "Processing: https://developers.google.com/machine-learning/crash-course\n",
      "Processing: http://research.google/blog/using-machine-learning-to-explore-neural-network-architecture/\n",
      "Processing: https://medium.com/geekculture/deep-learning-with-pytorch-part-1-what-is-deep-learning-9759d3fd46d4\n",
      "Processing: https://medium.com/@zacharypollatsek/pytorch-my-first-foray-into-deep-learning-faba8f2cdc44\n",
      "Processing: https://www.altexsoft.com/blog/pytorch-library/\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/1ajtyso/a_simple_explanation_of_pytorch/\n",
      "Processing: https://www.youtube.com/watch?v=V_xro1bcAuA\n",
      "Processing: https://medium.com/samsara-engineering/building-a-modern-machine-learning-platform-with-ray-eb0271f9cbcf\n",
      "Processing: https://www.anyscale.com/blog/why-you-should-build-your-ai-applications-with-ray\n",
      "Processing: https://www.infoq.com/presentations/ray-ml/\n",
      "Processing: https://medium.com/@erfan.loghmani/from-frustration-to-fast-using-ray-for-parallel-computing-on-a-single-machine-or-a-cluster-26233b2faabd\n",
      "Processing: https://www.reddit.com/r/mlops/comments/1bsuknq/opinions_of_ray_framework/\n",
      "Processing: https://www.ibm.com/think/topics/ai-vs-machine-learning-vs-deep-learning-vs-neural-networks\n",
      "Processing: https://www.ibm.com/topics/deep-learning\n",
      "Processing: https://www.ibm.com/topics/machine-learning\n",
      "Processing: https://admin02.prod.blogs.cis.ibm.net/blogs/think/category/machine-learning/\n",
      "Processing: https://developer.ibm.com/technologies/machine-learning/blogs/\n",
      "Processing: https://medium.com/codex/machine-learning-development-in-the-cloud-part-6-jobs-and-automation-2874dbd126b5\n",
      "Processing: https://www.reddit.com/r/MachineLearning/comments/ifn7ua/d_what_are_the_untold_truths_of_being_a_machine/\n",
      "Processing: https://www.fullstackacademy.com/blog/career-roadmap-to-get-into-ai-ml\n",
      "Processing: https://www.quora.com/Is-machine-learning-and-deep-learning-a-better-career-than-web-development-now\n",
      "Processing: https://medium.com/@vinodvamanbhat/devops-for-machine-learning-mlops-4fd280ca2ffd\n",
      "Processing: https://medium.com/oolooroo/role-of-ai-and-machine-learning-in-devops-c06c0035cf59\n",
      "Processing: https://www.icertglobal.com/how-devops-is-shaping-ai-ml-development-pipelines-blog/detail\n",
      "Processing: https://www.napkyn.com/blog/mlops-the-devops-of-machine-learning-systems\n",
      "Processing: https://www.linkedin.com/pulse/evolution-machine-learning-devops-bridging-gap-between-rajaram-j-lhvqc\n",
      "Processing: https://medium.com/@zakariasaif/demystifying-ai-and-ml-models-from-training-to-deployment-38179135d3e8\n",
      "Processing: https://synoptek.com/insights/it-blogs/data-insights/ai-ml-dl-and-generative-ai-face-off-a-comparative-analysis/\n",
      "Processing: https://nebius.com/blog/posts/what-is-automl\n",
      "Processing: https://www.clicdata.com/blog/ai-ml-data-science-deep-learning/\n",
      "Processing: https://online-engineering.case.edu/blog/advancements-in-artificial-intelligence-and-machine-learning\n",
      "Processing: https://mitsloan.mit.edu/ideas-made-to-matter/machine-learning-explained\n",
      "Processing: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
      "Processing: https://h2o.ai/blog/2019/a-deep-dive-into-h2os-automl/\n",
      "Processing: https://towardsdatascience.com/h2o-for-inexperienced-users-7bc064124264\n",
      "Processing: https://savemyleads.com/blog/useful/automl-automating-machine-learning\n",
      "Processing: https://www.analyticsvidhya.com/blog/2021/05/a-step-by-step-guide-to-automl-with-h2o-flow/\n",
      "Processing: https://neptune.ai/blog/mlops\n",
      "Processing: https://one2n.io/blog/understanding-mlops-from-a-software-engineers-perspective\n",
      "Processing: https://insights.sei.cmu.edu/blog/introduction-to-mlops-bridging-machine-learning-and-operations/\n",
      "Processing: https://www.acldigital.com/blogs/journey-machine-learning-towards-mlops\n",
      "Processing: https://medium.com/@faheemrustamy/machine-learning-platforms-using-kubeflow-a0a9be98f57f\n",
      "Processing: https://www.arrikto.com/blog/kubeflow-fundamentals-machine-learning-workflows-part-2/\n",
      "Processing: https://ubuntu.com/blog/deep-dive-kubeflow-pipelines\n",
      "Processing: https://medium.com/@saschagrunert/data-science-on-steroids-with-kubeflow-60fc3ba92b06\n",
      "Processing: https://blog.kubeflow.org/\n",
      "Processing: https://mlflow.org/blog/deep-learning-part-1\n",
      "Processing: https://www.run.ai/guides/machine-learning-operations/mlflow\n",
      "Processing: https://cloud4scieng.org/2022/07/08/understanding-mlops-a-review-of-practical-deep-learning-at-scale-with-mlflow-by-yong-liu/\n",
      "Processing: https://viso.ai/deep-learning/mlflow-machine-learning-experimentation/\n",
      "Processing: https://mlflow.org/blog/deep-learning-part-2\n",
      "Processing: https://medium.com/@shb8086/tutorial-series-onnx-a7044297991d\n",
      "Processing: https://medium.com/@hassini.abir/onnx-bridging-the-gap-between-different-machine-learning-frameworks-246593da3f09\n",
      "Processing: https://www.splunk.com/en_us/blog/learn/open-neural-network-exchange-onnx.html\n",
      "Processing: https://viso.ai/computer-vision/onnx-explained/\n",
      "Processing: https://www.linkedin.com/pulse/what-onnx-machine-learning-model-why-should-you-care-bhattiprolu\n",
      "Processing: https://neptune.ai/blog/tensorboard-tutorial\n",
      "Processing: https://medium.com/dscutsg/a-brief-introduction-to-tensorflow-for-machine-learning-aed3d19d1f55\n",
      "Processing: https://www.springboard.com/blog/data-science/tensorflow-tutorial-beginners/\n",
      "Processing: https://research.google/blog/build-your-own-machine-learning-visualizations-with-the-new-tensorboard-api/\n",
      "Processing: https://towardsdatascience.com/vibing-out-tensorflow-e91c04cc3872\n",
      "Processing: https://blogs.nvidia.com/deep-learning-fundamentals-explained/\n",
      "Processing: https://developer.nvidia.com/blog/profiling-and-optimizing-deep-neural-networks-with-dlprof-and-pyprof/\n",
      "Processing: https://medium.com/geekculture/deep-learning-gpu-setup-from-scratch-75f730c49c01\n",
      "Processing: https://developer.nvidia.com/blog/minimizing-dl-inference-latency-with-mig/\n",
      "Processing: https://neptune.ai/blog/machine-learning-approach-to-log-analytics\n",
      "Processing: https://medium.com/xenonstack-ai/automatic-log-analysis-using-deep-learning-and-ai-398759d01b2f\n",
      "Processing: https://sciencelogic.com/blog/log-analysis-with-machine-learning-an-automated-approach-to-analyzing-logs-using-ml-ai\n",
      "Processing: https://edgedelta.com/company/blog/how-log-analysis-is-evolving-with-ai-and-ml\n",
      "Processing: https://www.evidentlyai.com/ml-in-production/data-drift\n",
      "Processing: https://superwise.ai/blog/everything-you-need-to-know-about-drift-in-machine-learning/\n",
      "Processing: https://medium.com/@sachinsoni600517/understanding-and-detecting-drift-in-ml-models-58253f7968fe\n",
      "Processing: https://spotintelligence.com/2024/04/08/data-drift-in-machine-learning/\n",
      "Processing: https://medium.com/@gfcristhian98/understanding-model-drift-and-how-to-detect-it-effectively-305f27c734b2\n",
      "Processing: https://community.cadence.com/cadence_blogs_8/b/breakfast-bytes/posts/mlperf\n",
      "Processing: https://odsc.medium.com/what-is-mlperf-bf24ee72c309\n",
      "Processing: https://blogs.nvidia.com/blog/mlperf-training-blackwell/\n",
      "Processing: https://developer.nvidia.com/blog/leading-mlperf-training-2-1-with-full-stack-optimizations-for-ai/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://vente.medium.com/mlperf-vs-my-neural-net-training-time-nightmare-1a0a5ee624b6?source=post_internal_links---------4----------------------------\n",
      "Processing: https://www.analyticsvidhya.com/blog/2019/11/comprehensive-guide-attention-mechanism-deep-learning/\n",
      "Processing: https://www.kdnuggets.com/2021/01/attention-mechanism-deep-learning-explained.html\n",
      "Processing: https://medium.com/@prakhargannu/attention-mechanism-in-deep-learning-simplified-d6a5830a079d\n",
      "Processing: https://www.unthinkable.co/blog/exploring-the-concept-of-attention-mechanism-in-deep-learning/\n",
      "Processing: https://insights.daffodilsw.com/blog/what-is-the-attention-mechanism-in-deep-learning\n",
      "Processing: https://blogs.nvidia.com/blog/what-is-a-transformer-model/\n",
      "Processing: https://www.datacamp.com/tutorial/how-transformers-work\n",
      "Processing: https://www.turing.com/kb/brief-introduction-to-transformers-and-their-power\n",
      "Processing: https://blog.nelhage.com/post/transformers-for-software-engineers/\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/12r27jp/understanding_transformer_architecture/\n",
      "Processing: https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\n",
      "Processing: https://medium.com/@farzad.karami/decoding-the-magic-of-self-attention-a-deep-dive-into-its-intuition-and-mechanisms-394aa98f34c5\n",
      "Processing: https://www.geeksforgeeks.org/self-attention-in-nlp/\n",
      "Processing: https://www.reddit.com/r/deeplearning/comments/k5wn5k/resourcespapers_to_understand_transformers_and/\n",
      "Processing: https://www.scaler.com/topics/deep-learning/attention-mechanism-deep-learning/\n",
      "Processing: https://medium.com/@kramiknakrani100/deep-dive-into-multi-head-attention-revolutionizing-deep-learning-f9270eb5f30d\n",
      "Processing: https://data-science-blog.com/blog/2021/04/07/multi-head-attention-mechanism/\n",
      "Processing: https://theaisummer.com/self-attention/\n",
      "Processing: https://towardsdatascience.com/transformers-explained-visually-part-3-multi-head-attention-deep-dive-1c1ff1024853\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/lu9spi/multihead_attention_is_changing_deep_learning_in/\n",
      "Processing: https://medium.com/data-science-community-srm/understanding-encoders-decoders-with-attention-based-mechanism-c1eb7164c581\n",
      "Processing: https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n",
      "Processing: https://huggingface.co/blog/bert-101\n",
      "Processing: https://medium.com/@igniobydigitate/bert-a-beginner-friendly-explanation-876549f0ece2\n",
      "Processing: https://www.braveriver.com/blog/how-googles-bert-changed-natural-language-understanding/\n",
      "Processing: https://www.machinelearningmastery.com/a-brief-introduction-to-bert/\n",
      "Processing: https://blog.gregbrockman.com/how-i-became-a-machine-learning-practitioner\n",
      "Processing: https://www.springboard.com/blog/data-science/machine-learning-gpt-3-open-ai/\n",
      "Processing: https://www.einfochips.com/blog/openai-gpt-3-the-most-powerful-language-model-an-overview/\n",
      "Processing: https://aws.amazon.com/what-is/gpt/\n",
      "Processing: https://www.grammarly.com/blog/ai/what-is-gpt-3/\n",
      "Processing: https://medium.com/codecontent/introduction-to-llama-a-paradigm-shift-in-ai-language-models-0836c6048a05\n",
      "Processing: https://ai.meta.com/blog/large-language-model-llama-meta-ai/\n",
      "Processing: https://www.datacamp.com/blog/introduction-to-meta-ai-llama\n",
      "Processing: https://www.geeksforgeeks.org/what-is-llama/\n",
      "Processing: https://pauldeepakraj-r.medium.com/unraveling-the-limitations-of-llama-v2-an-in-depth-exploration-63a29bb3f723\n",
      "Processing: https://blog.google/technology/ai/google-gemini-ai/\n",
      "Processing: https://www.wovenware.com/blog/2024/02/gemini-ai-google-computer-vision-revolution/\n",
      "Processing: https://www.vlinkinfo.com/blog/gemini-ai-everything-you-need-to-know/\n",
      "Processing: https://www.zdnet.com/article/i-asked-gemini-and-gpt-4-to-explain-deep-learning-ai-and-gemini-won-hands-down/\n",
      "Processing: https://unfoldai.com/lessons-from-googles-gemini/\n",
      "Processing: https://medium.com/@tomskiecke/claude-ai-revolutionizing-web-development-fd675b52a05b\n",
      "Processing: https://www.reddit.com/r/ClaudeAI/comments/1e9nmkl/software_devs_how_are_you_preparingupskilling_for/\n",
      "Processing: https://618media.com/en/blog/the-science-behind-claude-ais-models/\n",
      "Processing: https://www.linkedin.com/pulse/cracking-code-how-claude-helping-release-my-inner-developer-moran-7rcbe\n",
      "Processing: https://idratherbewriting.com/blog/writing-full-length-articles-with-claude-ai\n",
      "Processing: https://research.ibm.com/blog/Granite-adapter-experiments\n",
      "Processing: https://syncedreview.com/2024/05/13/ibms-granite-code-powering-enterprise-software-development-with-ai-precision/\n",
      "Processing: https://www.datacamp.com/blog/what-is-prompt-engineering-the-future-of-ai-communication\n",
      "Processing: https://github.blog/ai-and-ml/generative-ai/prompt-engineering-guide-generative-ai-llms/\n",
      "Processing: https://www.altexsoft.com/blog/prompt-engineering/\n",
      "Processing: https://www.scrums.com/blog/the-differences-between-ai-prompt-and-software-engineers\n",
      "Processing: https://digitate.com/blog/what-is-prompt-engineering/\n",
      "Processing: https://medium.com/@mattchinnock/llms-and-machine-learning-for-software-engineers-a7634fab109a\n",
      "Processing: https://insights.sei.cmu.edu/blog/application-of-large-language-models-llms-in-software-engineering-overblown-hype-or-disruptive-change/\n",
      "Processing: https://dev.to/wesen/llms-will-fundamentally-change-software-engineering-3oj8\n",
      "Processing: https://blogs.nvidia.com/blog/what-are-large-language-models-used-for/\n",
      "Processing: https://zahere.com/demystifying-large-language-models-a-guide-for-software-developers\n",
      "Processing: https://www.machinelearningmastery.com/what-are-zero-shot-prompting-and-few-shot-prompting/\n",
      "Processing: https://www.ibm.com/topics/zero-shot-learning\n",
      "Processing: https://www.datacamp.com/tutorial/zero-shot-prompting\n",
      "Processing: https://www.vellum.ai/blog/zero-shot-vs-few-shot-prompting-a-guide-with-examples\n",
      "Processing: https://www.digital-adoption.com/zero-shot-prompting/\n",
      "Processing: https://softwareguide.medium.com/mastering-few-shot-prompting-a-comprehensive-guide-6eda3761538c\n",
      "Processing: https://learnprompting.org/docs/basics/few_shot?srsltid=AfmBOoq_hwuxpq2DVanTRoplAwEoZkUQvTA5HOyjl1RqBf14r-yOxg5w\n",
      "Processing: https://www.digital-adoption.com/what-is-few-shot-prompting-examples-uses/\n",
      "Processing: https://www.datacamp.com/tutorial/few-shot-prompting\n",
      "Processing: https://serokell.io/blog/chain-of-thought-prompting-llms\n",
      "Processing: https://towardsai.net/p/artificial-intelligence/understanding-chain-of-thought-cot-reasoning-the-core-behind-openais-o1-model\n",
      "Processing: http://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/\n",
      "Processing: https://annotationbox.com/chain-of-thought-prompting/\n",
      "Processing: https://www.prompthub.us/blog/chain-of-thought-prompting-guide\n",
      "Processing: https://medium.com/@vikrampande783/introduction-to-langchain-9e09aae37e62\n",
      "Processing: https://aws.amazon.com/what-is/langchain/\n",
      "Processing: https://www.useready.com/blog/building-better-llm-applications-with-langchain\n",
      "Processing: https://towardsai.net/p/l/understanding-langchain-%EF%B8%8F-part2\n",
      "Processing: https://medium.com/@gurinderjeetkaurnatt/generative-ai-with-langchain-ee9cc5078080\n",
      "Processing: https://medium.com/llamaindex-blog/llamaindex-metaphor-towards-automating-knowledge-work-with-llms-5520a32efa2f\n",
      "Processing: https://towardsai.net/p/artificial-intelligence/a-complete-guide-to-rag-and-llamaindex\n",
      "Processing: https://www.llamaindex.ai/blog/tag/machine-learning\n",
      "Processing: https://towardsai.net/p/machine-learning/unlocking-data-science-how-gemini-pro-and-llama-index-will-transform-your-workflow\n",
      "Processing: https://www.useready.com/blog/rag-wars-llama-index-vs-langchain-showdown\n",
      "Processing: https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/\n",
      "Processing: https://machine-learning-made-simple.medium.com/an-overview-of-how-to-do-retrieval-augmented-generation-3075292c0bed\n",
      "Processing: https://aws.amazon.com/what-is/retrieval-augmented-generation/\n",
      "Processing: https://medium.com/@ceo_44783/what-ive-learned-in-10-months-of-doing-rag-retrieval-augmented-generation-0520563ad256\n",
      "Processing: https://research.ibm.com/blog/retrieval-augmented-generation-RAG\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://medium.com/pinterest-engineering/understanding-pins-through-keyword-extraction-40cf94214c18\n",
      "Processing: https://www.seoclarity.net/blog/machine-learning-and-seo-16591/\n",
      "Processing: https://blog.google/products/search/search-language-understanding-bert/\n",
      "Processing: https://softwaredoug.com/blog/2024/06/25/what-ai-engineers-need-to-know-search\n",
      "Processing: https://www.quora.com/What-is-a-great-blog-for-machine-learning\n",
      "Processing: https://encord.com/blog/embeddings-machine-learning/\n",
      "Processing: https://medium.com/@alok.g.v/understanding-embedding-machine-learning-6b0712242bef\n",
      "Processing: https://developers.google.com/machine-learning/crash-course/embeddings\n",
      "Processing: https://aws.amazon.com/what-is/embeddings-in-machine-learning/\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/tfpl7c/a_deep_dive_into_word_embeddings_nlp/\n",
      "Processing: https://medium.com/@aikho/deep-learning-in-information-retrieval-part-ii-dense-retrieval-1f9fecb47de9\n",
      "Processing: https://www.amazon.science/blog/from-structured-search-to-learning-to-rank-and-retrieve\n",
      "Processing: https://github.com/sebastian-hofstaetter/teaching/blob/master/advanced-information-retrieval/Lecture%2010%20-%20Closed%20Captions.md\n",
      "Processing: https://news.ycombinator.com/item?id=39109469\n",
      "Processing: https://medium.com/womenintechnology/ai-c3412c5aa0ac\n",
      "Processing: https://towardsdatascience.com/deep-learning-and-machine-learning-c1101debe0c\n",
      "Processing: https://www.fullstackacademy.com/blog/what-is-deep-learning\n",
      "Processing: https://medium.com/cracking-the-data-science-interview/datacast-e117-vector-databases-the-embeddings-revolution-and-working-in-china-with-frank-liu-ebd7a157b49d\n",
      "Processing: https://lakefs.io/blog/what-is-vector-databases/\n",
      "Processing: https://zilliz.com/learn/what-is-vector-database\n",
      "Processing: https://www.pinecone.io/learn/vector-database/\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/1gte2j4/vector_databases_explained_in_2_minutes/\n",
      "Processing: https://machinelearningmastery.com/building-graph-rag-system-step-by-step-approach/\n",
      "Processing: https://medium.com/@sahin.samia/graph-rag-in-ai-what-is-it-and-how-does-it-work-d719d814e610\n",
      "Processing: https://www.linkedin.com/posts/elena-kohlwey-00924a14b_graphrag-field-guide-navigating-the-world-activity-7242436090630946816-wy0f\n",
      "Processing: https://towardsai.net/p/l/graphrag-is-the-logical-step-from-rag-so-why-the-sudden-hype\n",
      "Processing: https://markovate.com/agentic-rag/\n",
      "Processing: https://iamshobhitagarwal.medium.com/agentic-retrieval-augmented-generation-rag-a-comprehensive-guide-2872683fa773\n",
      "Processing: https://www.reddit.com/r/Rag/comments/1gqv7ei/rant_are_we_really_going_with_agentic_rag_now/\n",
      "Processing: https://blogs.nvidia.com/blog/what-is-a-pretrained-ai-model/\n",
      "Processing: https://stackoverflow.blog/2023/08/23/fitting-ai-models-in-your-pocket-with-quantization/\n",
      "Processing: https://soon-yau.medium.com/speeding-up-deep-learning-with-quantization-3fe3538cbb9\n",
      "Processing: https://www.reddit.com/r/learnmachinelearning/comments/1dkkg7z/one_of_my_first_blog_posts_quantization_basics/\n",
      "Processing: https://deepganteam.medium.com/three-flavors-of-quantization-cc5be18e7ab4\n",
      "Processing: https://towardsai.net/p/machine-learning/llm-quantization-intuition-simple-explaination\n",
      "Processing: https://sertiscorp.medium.com/machine-learning-engineer-vs-software-engineer-what-are-the-differences-a4047a8a8c2e\n",
      "Processing: https://parallelstaff.com/deep-learning-vs-machine-learning/\n",
      "Processing: https://www.edge-ai-vision.com/2024/05/fully-sharded-data-parallelism-fsdp/\n",
      "Processing: https://engineering.fb.com/2021/07/15/open-source/fsdp/\n",
      "Processing: https://medium.com/@siddharthashrestha/an-introduction-to-fsdp-fully-sharded-data-parallel-for-distributed-training-5e67adfa1712\n",
      "Processing: https://www.linkedin.com/posts/dr-akash-sri_from-deepspeed-to-fsdp-and-back-again-with-activity-7207125223622545408-pzXF\n",
      "Processing: https://www.linkedin.com/posts/chiravdave_distributed-training-demystified-a-beginner-activity-7263501075175882752-DY38\n",
      "Processing: https://medium.com/@sujathamudadla1213/zero-redundancy-optimization-zero-in-deep-learning-895a60f06a8c\n",
      "Processing: https://www.microsoft.com/en-us/research/blog/zero-deepspeed-new-system-optimizations-enable-training-models-with-over-100-billion-parameters/\n",
      "Processing: https://oracle-oci-ocas.medium.com/zero-redundancy-optimizers-a-method-for-training-machine-learning-models-with-billion-parameter-472e8f4e7a5b\n",
      "Processing: https://pub.towardsai.net/the-zero-redundancy-optimizer-zero-a-short-introduction-with-python-8db4fd07601d\n",
      "Processing: https://www.amazon.science/blog/making-deepspeed-zero-run-efficiently-on-more-affordable-hardware\n",
      "Processing: https://www.lesswrong.com/posts/6Fpvch8RR29qLEWNH/chinchilla-s-wild-implications\n",
      "Processing: https://www.linkedin.com/posts/barralexandra_chinchilla-explainedhow-to-read-deepminds-activity-7075517400284057600-6TT0\n",
      "Processing: https://medium.com/@ronnyh/research-paper-summary-chinchilla-training-compute-optimal-large-language-models-6073e0c83eb4\n",
      "Processing: https://www.graphcore.ai/posts/great-teachers-and-beyond-chinchilla-papers-of-the-month-jan-2024\n",
      "Processing: https://www.turing.com/kb/deepminds-chinchilla-ai\n",
      "Processing: https://medium.com/@genedarocha/what-is-the-development-of-bloomberggpt-860c0ab0d292\n",
      "Processing: https://snorkel.ai/blog/bloomberg-s-gideon-mann-on-the-power-of-domain-specialist-llms-bloomberggpt/\n",
      "Processing: https://www.linkedin.com/posts/pyquant-news_bloomberggpt-a-large-language-model-for-activity-7197991023124353025-dCX4\n",
      "Processing: https://medium.com/codex/bloomberggpt-the-first-large-language-model-for-finance-61cc92075075\n",
      "Processing: https://towardsai.net/p/l/bloomberggpt-the-first-gpt-for-finance\n",
      "Processing: https://medium.com/@amanatulla1606/fine-tuning-the-model-what-why-and-how-e7fa52bc8ddf\n",
      "Processing: https://www.ibm.com/topics/fine-tuning\n",
      "Processing: https://www.multimodal.dev/post/understanding-fine-tuning-in-deep-learning\n",
      "Processing: https://www.kdnuggets.com/2016/05/explain-machine-learning-software-engineer.html\n",
      "Processing: https://www.leewayhertz.com/parameter-efficient-fine-tuning/\n",
      "Processing: https://softwaremind.com/blog/parameter-efficient-fine-tuning-peft-benefits-and-techniques/\n",
      "Processing: https://www.ibm.com/think/topics/parameter-efficient-fine-tuning\n",
      "Processing: https://www.calibraint.com/blog/what-is-parameter-efficient-fine-tuning\n",
      "Processing: https://medium.com/intro-to-artificial-intelligence/parameter-efficient-finetuning-peft-of-llm-710831c0ffb3\n",
      "Processing: https://medium.com/@zhonghong9998/multi-task-learning-enhancing-model-efficiency-and-generalization-4d6f5ffd2fa7\n",
      "Processing: https://careersatdoordash.com/blog/improving-etas-with-multi-task-models-deep-learning-and-probabilistic-forecasts/\n",
      "Processing: https://www.ruder.io/multi-task/\n",
      "Processing: https://adasci.org/fine-tuning-pre-trained-multitask-llms-a-comprehensive-guide/\n",
      "Processing: https://towardsai.net/p/data-science/single-vs-multi-task-llm-instruction-fine-tuning\n",
      "Processing: https://www.ml6.eu/blogpost/low-rank-adaptation-a-technical-deep-dive\n",
      "Processing: https://www.linkedin.com/posts/zainhas_explanation-of-low-rank-adaptation-lora-activity-7223369220862922752-v0B4\n",
      "Processing: https://medium.com/@Shrishml/lora-low-rank-adaptation-from-the-first-principle-7e1adec71541\n",
      "Processing: https://datascientest.com/en/low-rank-adaptation-understanding-definition-applications-and-challenges\n",
      "Processing: https://medium.com/@adimodi96/low-rank-adaptation-lora-explained-9e64b7b0a5f1\n",
      "Processing: https://developer.nvidia.com/blog/an-introduction-to-large-language-models-prompt-engineering-and-p-tuning/\n",
      "Processing: https://dev.to/avinashvagh/understanding-the-concept-of-natural-language-processing-nlp-and-prompt-engineering-35hg\n",
      "Processing: https://medium.com/@dillipprasad60/qlora-explained-a-deep-dive-into-parametric-efficient-fine-tuning-in-large-language-models-llms-c1a4794b1766\n",
      "Processing: https://www.reddit.com/r/MachineLearning/comments/15lnfbh/a_blog_on_lora_and_qlora_finetuning_techniques_p/\n",
      "Processing: https://www.brev.dev/blog/how-qlora-works\n",
      "Processing: https://towardsdatascience.com/leveraging-qlora-for-fine-tuning-of-task-fine-tuned-models-without-catastrophic-forgetting-d9bcd594cff4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: https://www.linkedin.com/posts/optimumai_peft-newsletter-ai-activity-7201972096032272384-uGEa\n",
      "Processing: https://medium.com/nlplanet/two-minutes-nlp-learn-the-rouge-metric-by-examples-f179cc285499\n",
      "Processing: https://www.traceloop.com/blog/evaluating-model-performance-with-the-rouge-metric-a-comprehensive-guide\n",
      "Processing: https://www.linkedin.com/advice/1/what-rouge-score-how-can-you-use-evaluate-nlp-euj9e\n",
      "Processing: https://towardsdatascience.com/to-rouge-or-not-to-rouge-6a5f3552ea45\n",
      "Processing: https://medium.com/free-code-camp/what-is-rouge-and-how-it-works-for-evaluation-of-summaries-e059fb8ac840\n",
      "Processing: https://kantanmtblog.com/2015/07/14/understanding-bleu-for-machine-translation/\n",
      "Processing: https://www.traceloop.com/blog/demystifying-the-bleu-metric\n",
      "Processing: https://kvashee.medium.com/understanding-mt-quality-bleu-scores-9a19ed20526d\n",
      "Processing: https://towardsdatascience.com/evaluating-text-output-in-nlp-bleu-at-your-own-risk-e8609665a213\n",
      "Processing: https://medium.com/@sthanikamsanthosh1994/understanding-bleu-and-rouge-score-for-nlp-evaluation-1ab334ecadcb\n",
      "Processing: https://encord.com/blog/f1-score-in-machine-learning/\n",
      "Processing: https://arize.com/blog-course/f1-score/\n",
      "Processing: https://serokell.io/blog/a-guide-to-f1-score\n",
      "Processing: https://www.v7labs.com/blog/f1-score-guide\n",
      "Processing: https://www.geeksforgeeks.org/f1-score-in-machine-learning/\n",
      "Processing: https://www.noidea.dog/glue\n",
      "Processing: https://h2o.ai/wiki/glue/\n",
      "Processing: https://medium.com/@pradoshkumar.jena/understanding-benchmarking-in-nlp-glue-superglue-helm-mmlu-and-big-bench-2e0a55b57d3b\n",
      "Processing: https://aws.amazon.com/blogs/machine-learning/category/analytics/aws-glue/\n",
      "Processing: https://venturebeat.com/ai/ai-researchers-launch-superglue-a-rigorous-benchmark-for-language-understanding/\n",
      "Processing: https://www.interviewquery.com/p/software-engineering-vs-machine-learning\n",
      "Processing: https://newsletter.pragmaticengineer.com/p/what-is-ml-engineering\n",
      "Processing: https://christiangrech.medium.com/unlock-faster-llm-serving-with-vllm-a-step-by-step-guide-331afc2f5bf5\n",
      "Processing: https://medium.com/@asimsultan2/vllm-a-deep-dive-into-efficient-llm-inference-and-serving-17804bf047df\n",
      "Processing: http://muratbuffalo.blogspot.com/2016/12/learning-machine-learning-beginners.html\n",
      "Processing: https://encord.com/blog/vision-language-models-guide/\n",
      "Processing: https://community.nasscom.in/index.php/communities/ai/understanding-vllm-virtual-large-language-model-revolution\n",
      "Processing: https://towardsdatascience.com/deepspeed-deep-dive-model-implementations-for-inference-mii-b02aa5d5e7f7\n",
      "Processing: https://www.ideas2it.com/blogs/deepspeed-mii-made-easy\n",
      "Processing: https://www.deepspeed.ai/\n",
      "Processing: https://medium.com/design-bootcamp/advancing-machine-learning-with-deepspeed-mii-and-stable-diffusion-c65f3960ac4b\n",
      "Processing: https://www.microsoft.com/en-us/research/project/deepspeed/microsoft-research-blog/\n",
      "Processing: https://developer.nvidia.com/blog/deploying-deep-learning-nvidia-tensorrt/\n",
      "Processing: https://medium.com/@abhilashkrish/deep-dive-into-nvidia-tensorrt-model-parsing-optimization-and-high-performance-inference-07af563d0f8d\n",
      "Processing: https://blog.roboflow.com/what-is-tensorrt/\n",
      "Processing: https://medium.com/the-techlife/tensorrt-an-overview-2023-ce32cb9509dc\n",
      "Processing: https://developer.nvidia.com/blog/optimizing-and-serving-models-with-nvidia-tensorrt-and-nvidia-triton/\n",
      "Processing: https://www.datacamp.com/tutorial/hugging-faces-text-generation-inference-toolkit-for-llms\n",
      "Processing: https://huggingface.co/blog\n",
      "Processing: https://www.ideas2it.com/blogs/deploying-llm-powered-applications-in-production-using-tgi\n",
      "Processing: https://www.linkedin.com/posts/jeffboudier_github-huggingfacetext-generation-inference-activity-7090755444129861632-NWj2\n",
      "Processing: https://huggingface.co/blog/community\n",
      "Processing: https://blogs.rstudio.com/tensorflow/posts/2023-06-22-understanding-lora/\n",
      "Processing: https://medium.com/@meghanheintz/gentle-introduction-to-lora-low-rank-adaptation-for-finetuning-167be61731a6\n",
      "Processing: https://www.machinelearningmastery.com/using-lora-in-stable-diffusion/\n",
      "Processing: https://mlsys.stanford.edu/\n",
      "Processing: https://www.quora.com/Do-deep-learning-machine-learning-professionals-test-run-their-codes-on-their-own-laptop-or-on-a-remote-computer-cloud\n",
      "Processing: https://aws.amazon.com/blogs/machine-learning/efficient-and-cost-effective-multi-tenant-lora-serving-with-amazon-sagemaker/\n",
      "Processing: https://huggingface.co/blog/rlhf\n",
      "Processing: https://codingscape.com/blog/what-is-rlhf-reinforcement-learning-from-human-feedback\n",
      "Processing: https://blog.pangeanic.com/what-is-reinforcement-learning-from-human-feedback-rlhf-how-it-works\n",
      "Processing: https://www.lakera.ai/blog/reinforcement-learning-from-human-feedback\n",
      "Processing: https://aws.amazon.com/blogs/machine-learning/improving-your-llms-with-rlhf-on-amazon-sagemaker/\n",
      "Processing: https://www.reddit.com/r/reinforcementlearning/comments/gs2mj5/blog_series_on_proximal_policy_optimization/\n",
      "Processing: https://medium.com/@chris.p.hughes10/understanding-ppo-a-game-changer-in-ai-decision-making-explained-for-rl-newcomers-913a0bc98d2b\n",
      "Processing: https://medium.com/intro-to-artificial-intelligence/proximal-policy-optimization-ppo-a-policy-based-reinforcement-learning-algorithm-3cf126a7562d\n",
      "Processing: https://datascientest.com/en/proximal-policy-optimization-all-about-the-algorithm-created-by-openai\n",
      "Processing: https://towardsdatascience.com/breaking-down-state-of-the-art-ppo-implementations-in-jax-6f102c06c149\n",
      "Processing: https://medium.com/@jonnyndavis/understanding-constitutional-ai-dd9d783ef712\n",
      "Processing: https://www.solventum.com/en-us/home/health-information-technology/resources-education/blog/2023/6/ai-talk-naturalness-of-software-and-constitutional-ai/\n",
      "Processing: https://medium.com/@lekefbi/constitutional-ai-for-harmless-ai-a3d76cb79149\n",
      "Processing: https://www.cornelllawreview.org/wp-content/uploads/2020/12/Huq-final.pdf\n",
      "Processing: https://arxiv.org/abs/2212.08073\n"
     ]
    }
   ],
   "source": [
    "extracted_google_blog_data = process_links(all_google_blog_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "3391565f",
   "metadata": {},
   "outputs": [],
   "source": [
    "links_dict = defaultdict(lambda: \"\")\n",
    "for key,value in cleaned_extracted_data.items():\n",
    "    links_dict[key] = value\n",
    "for key,value in cleaned_extracted_hw_data.items():\n",
    "    links_dict[key] = value\n",
    "for key,value in extracted_google_blog_data.items():\n",
    "    links_dict[key] = value\n",
    "cleaned_links_dict = {key:value for key, value in links_dict.items() if len(value)>=1000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfa9688",
   "metadata": {},
   "source": [
    "<h1>6. Chunking scraped data from links for VDB</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "e866eab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_into_sentences(text: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split text into sentences using a regex-based sentence tokenizer.\n",
    "    \"\"\"\n",
    "    sentence_endings = re.compile(r'(?<=[.!?]) +')  # Match end of sentence followed by space\n",
    "    return sentence_endings.split(text)\n",
    "\n",
    "def chunk_text_by_sentence(text: str, max_tokens: int, tokenizer) -> List[str]:\n",
    "    \"\"\"\n",
    "    Chunk text into pieces of max_tokens length, ensuring chunks do not cut sentences.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The input text to chunk.\n",
    "        max_tokens (int): The maximum number of tokens per chunk.\n",
    "        tokenizer: The tokenizer instance for tokenizing the text.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: A list of text chunks.\n",
    "    \"\"\"\n",
    "    sentences = split_into_sentences(text)\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    current_tokens = 0\n",
    "    for sentence in sentences:\n",
    "        sentence_tokens = tokenizer.encode(sentence)\n",
    "        if current_tokens + len(sentence_tokens) <= max_tokens:\n",
    "            current_chunk.append(sentence)\n",
    "            current_tokens += len(sentence_tokens)\n",
    "        else:\n",
    "            # Complete the current chunk\n",
    "            if current_chunk:\n",
    "                chunks.append(\" \".join(current_chunk))\n",
    "            # Start a new chunk\n",
    "            current_chunk = [sentence]\n",
    "            current_tokens = len(sentence_tokens)\n",
    "\n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "def chunk_documents_by_sentence(documents: Dict[str, str], max_tokens: int = 500) -> Dict[str, List[str]]:\n",
    "    \"\"\"\n",
    "    Chunk the text of multiple documents into smaller pieces, ensuring no sentence is cut.\n",
    "    \n",
    "    Args:\n",
    "        documents (Dict[str, str]): A dictionary with document IDs as keys and text as values.\n",
    "        max_tokens (int): The maximum number of tokens per chunk.\n",
    "    \n",
    "    Returns:\n",
    "        Dict[str, List[str]]: A dictionary with document IDs as keys and lists of chunked text as values.\n",
    "    \"\"\"\n",
    "    tokenizer = tiktoken.get_encoding(\"cl100k_base\")  # Use the tokenizer compatible with OpenAI models\n",
    "    chunked_documents = {}\n",
    "    \n",
    "    for doc_id, text in documents.items():\n",
    "        chunked_documents[doc_id] = chunk_text_by_sentence(text, max_tokens, tokenizer)\n",
    "    \n",
    "    return chunked_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "1b501cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunked_links_dict = chunk_documents_by_sentence(cleaned_links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "140db7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"data_from_embedded_links.json\"\n",
    "with open(file_name, \"w\") as json_file:\n",
    "    json.dump(chunked_links_dict, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa52cc07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2231116",
   "metadata": {},
   "source": [
    "<h1>7. Building new synthetic Q and A set from scraped links text</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "9dd0566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "10f8e88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embedded_blogs = list(cleaned_links_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "b2d0d68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_q_a_string_json(text):\n",
    "    clean_response = text.strip('```python\\n').strip('```')\n",
    "    try:\n",
    "        quiz_data = ast.literal_eval(clean_response)\n",
    "        return quiz_data\n",
    "    except Exception as e:\n",
    "        print(\"Error parsing the response:\", e)\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abaa58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_q_a = []\n",
    "for key,value in links_dict.items():\n",
    "    try:\n",
    "        start = timeit.default_timer()\n",
    "        all_messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"I am trying to create a dataset of quiz questions and answers I can use to fine-tune a model. I want you to create that set of up to 10 open ended quiz questions and answers using the data I give you below\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Here is the data I want you to make quiz questions and answers from: {value}.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Please make sure to only make questions related to Machine Learning, Large Language Models, Computer Science, and Software Engineering topics\"},\n",
    "        {\"role\": \"user\", \"content\": \"Please format the output as a list of python dictionaries where each dictionary represents one question answer pair. Here is an example of the structure [{'question':extracted question, 'answer':extracted answer}]\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Please return nothing else other than a string version of the python dictionary\"}\n",
    "        ]\n",
    "        response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4o\",\n",
    "        max_tokens = 8000,\n",
    "        messages=all_messages\n",
    "        )\n",
    "        q_a_json_text = response['choices'][0]['message']['content']\n",
    "        q_a_list = clean_q_a_string_json(q_a_json_text)\n",
    "        all_q_a = all_q_a + q_a_list\n",
    "        end = timeit.default_timer()\n",
    "        print(end-start,key,q_a_list,len(all_q_a))\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "4b7d8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_q_and_a_docs_final = []\n",
    "for q_a in all_q_a:\n",
    "    all_keys = q_a.keys()\n",
    "    if ('question' in all_keys)&('answer' in all_keys):\n",
    "        all_q_and_a_docs_final.append({'input':q_a['question'],'output':q_a['answer']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "74c4ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_q_and_a_docs_final_cleaned = np.array([q_a if \"?\" in q_a['input'] else {\"input\":f\"What is {q_a['input']}?\",\"output\":q_a['output']} for q_a in all_q_and_a_docs_final ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "0ba5e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_indices = np.arange(0,len(all_q_and_a_docs_final_cleaned))\n",
    "train_indices = np.random.choice(all_indices, size = int(len(all_q_and_a_docs_final_cleaned)*.6))\n",
    "test_indices = np.array([index for index in all_indices if index not in train_indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "dd5b0e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = all_q_and_a_docs_final_cleaned[train_indices]\n",
    "test_data = all_q_and_a_docs_final_cleaned[test_indices]\n",
    "test_data_list = list(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "426933de",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"./Test Data/test_data.json\"\n",
    "with open(file_name, \"w\") as json_file:\n",
    "    json.dump(test_data_list, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "c7cab926",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./Fine Tuning Data/training_data.jsonl\"\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for line in training_data:\n",
    "        try:\n",
    "            # Parse the JSON line\n",
    "            # Create the required structure\n",
    "            transformed = {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": line.get(\"input\", \"\")}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"model\",\n",
    "                        \"parts\": [{\"text\": line.get(\"output\", \"\")}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            # Write the transformed JSON object as a line\n",
    "            outfile.write(json.dumps(transformed) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {line.strip()}\\nError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "80ad7d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./Fine Tuning Data/test_data.jsonl\"\n",
    "with open(output_file, 'w') as outfile:\n",
    "    for line in test_data:\n",
    "        try:\n",
    "            # Parse the JSON line\n",
    "            # Create the required structure\n",
    "            transformed = {\n",
    "                \"contents\": [\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"parts\": [{\"text\": line.get(\"input\", \"\")}]\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"model\",\n",
    "                        \"parts\": [{\"text\": line.get(\"output\", \"\")}]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "            # Write the transformed JSON object as a line\n",
    "            outfile.write(json.dumps(transformed) + \"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing line: {line.strip()}\\nError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "c62f01da",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_formatted_data = []\n",
    "for entry in training_data:\n",
    "    formatted_entry = {\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful tutor who answers questions about a class called Introduction to Deep Learning and LLM based Generative AI Systems\"},\n",
    "            {\"role\": \"user\", \"content\": entry[\"input\"]},\n",
    "            {\"role\": \"assistant\", \"content\": entry[\"output\"]}\n",
    "        ]\n",
    "    }\n",
    "    openai_formatted_data.append(formatted_entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "a07bf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./Fine Tuning Data/openai_training_data.jsonl\", \"w\") as f:\n",
    "    for entry in openai_formatted_data:\n",
    "        f.write(json.dumps(entry) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "cef20ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.File.create(\n",
    "    file=open(\"./Fine Tuning Data/openai_training_data.jsonl\", \"rb\"),\n",
    "    purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7feaa251",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vertexai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
